'use strict';

Object.defineProperty(exports, '__esModule', { value: true });

var catalogModel = require('@backstage/catalog-model');
var errors = require('@backstage/errors');
var lodash = require('lodash');
var limiterFactory = require('p-limit');
var backendCommon = require('@backstage/backend-common');
var knexFactory = require('knex');
var uuid = require('uuid');
var integration = require('@backstage/integration');
var parseGitUrl = require('git-url-parse');
var AWS = require('aws-sdk');
var fetch = require('cross-fetch');
require('core-js/features/promise');
var codeowners = require('codeowners-utils');
var fp = require('lodash/fp');
var fs = require('fs-extra');
var g = require('glob');
var path = require('path');
var util = require('util');
var yaml = require('yaml');
var graphql = require('@octokit/graphql');
var ldap = require('ldapjs');
var mergeWith = require('lodash/mergeWith');
var lodashSet = require('lodash/set');
var msal = require('@azure/msal-node');
var qs = require('qs');
var express = require('express');
var Router = require('express-promise-router');
var yn = require('yn');
var crypto = require('crypto');
var stableStringify = require('fast-json-stable-stringify');

function _interopDefaultLegacy (e) { return e && typeof e === 'object' && 'default' in e ? e : { 'default': e }; }

var lodash__default = /*#__PURE__*/_interopDefaultLegacy(lodash);
var limiterFactory__default = /*#__PURE__*/_interopDefaultLegacy(limiterFactory);
var knexFactory__default = /*#__PURE__*/_interopDefaultLegacy(knexFactory);
var parseGitUrl__default = /*#__PURE__*/_interopDefaultLegacy(parseGitUrl);
var AWS__default = /*#__PURE__*/_interopDefaultLegacy(AWS);
var fetch__default = /*#__PURE__*/_interopDefaultLegacy(fetch);
var fs__default = /*#__PURE__*/_interopDefaultLegacy(fs);
var g__default = /*#__PURE__*/_interopDefaultLegacy(g);
var path__default = /*#__PURE__*/_interopDefaultLegacy(path);
var yaml__default = /*#__PURE__*/_interopDefaultLegacy(yaml);
var ldap__default = /*#__PURE__*/_interopDefaultLegacy(ldap);
var mergeWith__default = /*#__PURE__*/_interopDefaultLegacy(mergeWith);
var lodashSet__default = /*#__PURE__*/_interopDefaultLegacy(lodashSet);
var qs__default = /*#__PURE__*/_interopDefaultLegacy(qs);
var express__default = /*#__PURE__*/_interopDefaultLegacy(express);
var Router__default = /*#__PURE__*/_interopDefaultLegacy(Router);
var yn__default = /*#__PURE__*/_interopDefaultLegacy(yn);
var stableStringify__default = /*#__PURE__*/_interopDefaultLegacy(stableStringify);

function basicEntityFilter(items) {
  const filtersByKey = {};
  for (const [key, value] of Object.entries(items)) {
    const values = [value].flat();
    const f = key in filtersByKey ? filtersByKey[key] : filtersByKey[key] = {key, matchValueIn: []};
    f.matchValueIn.push(...values);
  }
  return {anyOf: [{allOf: Object.values(filtersByKey)}]};
}

function parseIntegerParam(param, ctx) {
  if (param === void 0) {
    return void 0;
  }
  if (typeof param !== "string") {
    throw new errors.InputError(`Invalid ${ctx}, not an integer on string form`);
  }
  const parsed = parseInt(param, 10);
  if (!Number.isInteger(parsed) || String(parsed) !== param) {
    throw new errors.InputError(`Invalid ${ctx}, not an integer`);
  }
  return parsed;
}
function parseStringParam(param, ctx) {
  if (param === void 0) {
    return void 0;
  }
  if (typeof param !== "string") {
    throw new errors.InputError(`Invalid ${ctx}, not a string`);
  }
  return param;
}
function parseStringsParam(param, ctx) {
  if (param === void 0) {
    return void 0;
  }
  const array = [param].flat();
  if (array.some((p) => typeof p !== "string")) {
    throw new errors.InputError(`Invalid ${ctx}, not a string`);
  }
  return array;
}

function parseEntityFilterParams(params) {
  const filterStrings = parseStringsParam(params.filter, "filter");
  if (!filterStrings) {
    return void 0;
  }
  const filters = filterStrings.map(parseEntityFilterString).filter(Boolean);
  if (!filters.length) {
    return void 0;
  }
  return {anyOf: filters.map((f) => ({allOf: f}))};
}
function parseEntityFilterString(filterString) {
  const statements = filterString.split(",").map((s) => s.trim()).filter(Boolean);
  if (!statements.length) {
    return void 0;
  }
  const filtersByKey = {};
  for (const statement of statements) {
    const equalsIndex = statement.indexOf("=");
    if (equalsIndex < 1) {
      throw new errors.InputError(`Invalid filter, '${statement}' is not a valid statement (expected a string on the form a=b)`);
    }
    const key = statement.substr(0, equalsIndex).trim();
    const value = statement.substr(equalsIndex + 1).trim();
    if (!key || !value) {
      throw new errors.InputError(`Invalid filter, '${statement}' is not a valid statement (expected a string on the form a=b)`);
    }
    const f = key in filtersByKey ? filtersByKey[key] : filtersByKey[key] = {key, matchValueIn: []};
    f.matchValueIn.push(value);
  }
  return Object.values(filtersByKey);
}

function parseEntityPaginationParams(params) {
  const offset = parseIntegerParam(params.offset, "offset");
  const limit = parseIntegerParam(params.limit, "limit");
  const after = parseStringParam(params.after, "after");
  if (offset === void 0 && limit === void 0 && after === void 0) {
    return void 0;
  }
  if (offset !== void 0 && offset < 0) {
    throw new errors.InputError(`Invalid offset, must be zero or greater`);
  }
  if (limit !== void 0 && limit <= 0) {
    throw new errors.InputError(`Invalid limit, must be greater than zero`);
  }
  if (after !== void 0 && !after) {
    throw new errors.InputError(`Invalid after, must not be empty`);
  }
  return {
    ...offset !== void 0 ? {offset} : {},
    ...limit !== void 0 ? {limit} : {},
    ...after !== void 0 ? {after} : {}
  };
}

function parseEntityTransformParams(params) {
  const fieldsStrings = parseStringsParam(params.fields, "fields");
  if (!fieldsStrings) {
    return void 0;
  }
  const fields = fieldsStrings.map((s) => s.split(",")).flat().map((s) => s.trim()).filter(Boolean);
  if (!fields.length) {
    return void 0;
  }
  if (fields.some((f) => f.includes("["))) {
    throw new errors.InputError("invalid fields, array type fields are not supported");
  }
  return (input) => {
    const output = {};
    for (const field of fields) {
      const value = lodash__default['default'].get(input, field);
      if (value !== void 0) {
        lodash__default['default'].set(output, field, value);
      }
    }
    return output;
  };
}

function durationText(startTimestamp) {
  const delta = process.hrtime(startTimestamp);
  const seconds = delta[0] + delta[1] / 1e9;
  if (seconds > 1) {
    return `${seconds.toFixed(1)}s`;
  }
  return `${(seconds * 1e3).toFixed(0)}ms`;
}

const BATCH_SIZE = 100;
const BATCH_ATTEMPTS = 3;
const BATCH_CONCURRENCY = 3;
class DatabaseEntitiesCatalog {
  constructor(database, logger) {
    this.database = database;
    this.logger = logger;
  }
  async entities(request) {
    const dbRequest = {
      filter: request == null ? void 0 : request.filter,
      pagination: request == null ? void 0 : request.pagination
    };
    const dbResponse = await this.database.transaction((tx) => this.database.entities(tx, dbRequest));
    const entities = dbResponse.entities.map((e) => (request == null ? void 0 : request.fields) ? request.fields(e.entity) : e.entity);
    return {
      entities,
      pageInfo: dbResponse.pageInfo
    };
  }
  async removeEntityByUid(uid) {
    await this.database.transaction(async (tx) => {
      await this.database.removeEntityByUid(tx, uid);
    });
  }
  async batchAddOrUpdateEntities(requests, options) {
    const requestsByKindAndNamespace = lodash.groupBy(requests, ({entity}) => {
      const name = catalogModel.getEntityName(entity);
      return `${name.kind}:${name.namespace}`.toLowerCase();
    });
    const batches = Object.values(requestsByKindAndNamespace).map((request) => lodash.chunk(request, BATCH_SIZE)).flat();
    const limiter = limiterFactory__default['default'](BATCH_CONCURRENCY);
    const tasks = batches.map((batch) => limiter(async () => {
      for (let attempt = 1; ; ++attempt) {
        try {
          return this.batchAddOrUpdateEntitiesSingleBatch(batch, options);
        } catch (e) {
          if (e instanceof errors.ConflictError && attempt < BATCH_ATTEMPTS) {
            this.logger.warn(`Failed to write batch at attempt ${attempt}/${BATCH_ATTEMPTS}, ${e}`);
          } else {
            throw e;
          }
        }
      }
    }));
    const responses = await Promise.all(tasks);
    return responses.flat();
  }
  async batchAddOrUpdateEntitiesSingleBatch(batch, options) {
    const {kind, namespace} = catalogModel.getEntityName(batch[0].entity);
    const context = {
      kind,
      namespace,
      locationId: options == null ? void 0 : options.locationId
    };
    this.logger.debug(`Considering batch ${catalogModel.serializeEntityRef(batch[0].entity)}-${catalogModel.serializeEntityRef(batch[batch.length - 1].entity)} (${batch.length} entries)`);
    return this.database.transaction(async (tx) => {
      const {toAdd, toUpdate, toIgnore} = await this.analyzeBatch(batch, context, tx);
      let responses = new Array();
      if (toAdd.length) {
        const items = await this.batchAdd(toAdd, context, tx);
        responses.push(...items);
      }
      if (toUpdate.length) {
        const items = await this.batchUpdate(toUpdate, context, tx);
        responses.push(...items);
      }
      for (const {entity, relations} of toIgnore) {
        const entityId = entity.metadata.uid;
        if (entityId) {
          await this.database.setRelations(tx, entityId, relations);
          responses.push({entityId});
        }
      }
      if ((options == null ? void 0 : options.outputEntities) && responses.length > 0) {
        const writtenEntities = await this.database.entities(tx, {
          filter: basicEntityFilter({
            "metadata.uid": responses.map((e) => e.entityId)
          })
        });
        responses = writtenEntities.entities.map((e) => ({
          entityId: e.entity.metadata.uid,
          entity: e.entity
        }));
      }
      if (options == null ? void 0 : options.dryRun) {
        await tx.rollback();
        this.logger.debug(`Performed successful dry run of adding entities`);
      }
      return responses;
    });
  }
  async analyzeBatch(requests, {kind, namespace}, tx) {
    var _a, _b;
    const markTimestamp = process.hrtime();
    const names = requests.map(({entity}) => entity.metadata.name);
    const oldEntitiesResponse = await this.database.entities(tx, {
      filter: basicEntityFilter({
        kind,
        "metadata.namespace": namespace,
        "metadata.name": names
      })
    });
    const oldEntitiesByName = new Map(oldEntitiesResponse.entities.map((e) => [e.entity.metadata.name, e.entity]));
    const toAdd = [];
    const toUpdate = [];
    const toIgnore = [];
    for (const request of requests) {
      const newEntity = request.entity;
      const oldEntity = oldEntitiesByName.get(newEntity.metadata.name);
      const newLocation = (_a = newEntity.metadata.annotations) == null ? void 0 : _a[catalogModel.LOCATION_ANNOTATION];
      const oldLocation = (_b = oldEntity == null ? void 0 : oldEntity.metadata.annotations) == null ? void 0 : _b[catalogModel.LOCATION_ANNOTATION];
      if (!oldEntity) {
        toAdd.push(request);
      } else if (oldLocation !== newLocation) {
        this.logger.warn(`Rejecting write of entity ${catalogModel.serializeEntityRef(newEntity)} from ${newLocation} because entity existed from ${oldLocation}`);
        toIgnore.push(request);
      } else if (catalogModel.entityHasChanges(oldEntity, newEntity)) {
        toUpdate.push(request);
      } else {
        toIgnore.push({...request, entity: oldEntity});
      }
    }
    this.logger.debug(`Found ${toAdd.length} entities to add, ${toUpdate.length} entities to update in ${durationText(markTimestamp)}`);
    return {toAdd, toUpdate, toIgnore};
  }
  async batchAdd(requests, {locationId}, tx) {
    const markTimestamp = process.hrtime();
    const res = await this.database.addEntities(tx, requests.map(({entity, relations}) => ({
      locationId,
      entity,
      relations
    })));
    const responses = res.map(({entity}) => ({
      entityId: entity.metadata.uid
    }));
    this.logger.debug(`Added ${requests.length} entities in ${durationText(markTimestamp)}`);
    return responses;
  }
  async batchUpdate(requests, {locationId}, tx) {
    const markTimestamp = process.hrtime();
    const responses = [];
    for (const request of requests) {
      const res = await this.addOrUpdateEntity(tx, request, locationId);
      const entityId = res.metadata.uid;
      responses.push({entityId});
    }
    this.logger.debug(`Updated ${requests.length} entities in ${durationText(markTimestamp)}`);
    return responses;
  }
  async addOrUpdateEntity(tx, {entity, relations}, locationId) {
    const existing = entity.metadata.uid ? await this.database.entityByUid(tx, entity.metadata.uid) : await this.database.entityByName(tx, catalogModel.getEntityName(entity));
    let response;
    if (existing) {
      const updated = catalogModel.generateUpdatedEntity(existing.entity, entity);
      response = await this.database.updateEntity(tx, {locationId, entity: updated, relations}, existing.entity.metadata.etag, existing.entity.metadata.generation);
    } else {
      const added = await this.database.addEntities(tx, [
        {locationId, entity, relations}
      ]);
      response = added[0];
    }
    return response.entity;
  }
}

var DatabaseLocationUpdateLogStatus;
(function(DatabaseLocationUpdateLogStatus2) {
  DatabaseLocationUpdateLogStatus2["FAIL"] = "fail";
  DatabaseLocationUpdateLogStatus2["SUCCESS"] = "success";
})(DatabaseLocationUpdateLogStatus || (DatabaseLocationUpdateLogStatus = {}));

class DatabaseLocationsCatalog {
  constructor(database) {
    this.database = database;
  }
  async addLocation(location) {
    return await this.database.transaction(async (tx) => await this.database.addLocation(tx, location));
  }
  async removeLocation(id) {
    await this.database.transaction((tx) => this.database.removeLocation(tx, id));
  }
  async locations() {
    const items = await this.database.locations();
    return items.map(({message, status, timestamp, ...data}) => ({
      currentStatus: {
        message,
        status,
        timestamp
      },
      data
    }));
  }
  async locationHistory(id) {
    return this.database.locationHistory(id);
  }
  async location(id) {
    const {
      message,
      status,
      timestamp,
      ...data
    } = await this.database.location(id);
    return {
      currentStatus: {
        message,
        status,
        timestamp
      },
      data
    };
  }
  async logUpdateSuccess(locationId, entityName) {
    await this.database.addLocationUpdateLogEvent(locationId, DatabaseLocationUpdateLogStatus.SUCCESS, entityName);
  }
  async logUpdateFailure(locationId, error, entityName) {
    await this.database.addLocationUpdateLogEvent(locationId, DatabaseLocationUpdateLogStatus.FAIL, entityName, error == null ? void 0 : error.message);
  }
}

const SPECIAL_KEYS = [
  "metadata.name",
  "metadata.namespace",
  "metadata.uid",
  "metadata.etag",
  "metadata.generation"
];
const MAX_KEY_LENGTH = 200;
const MAX_VALUE_LENGTH = 200;
function traverse(root) {
  const output = [];
  function visit(path, current) {
    if (SPECIAL_KEYS.includes(path)) {
      return;
    }
    if (current === void 0 || current === null || ["string", "number", "boolean"].includes(typeof current)) {
      output.push({key: path, value: current});
      return;
    }
    if (typeof current !== "object") {
      return;
    }
    if (Array.isArray(current)) {
      for (const item of current) {
        visit(path, item);
        if (typeof item === "string") {
          output.push({key: `${path}.${item}`, value: true});
        }
      }
      return;
    }
    for (const [key, value] of Object.entries(current)) {
      visit(path ? `${path}.${key}` : key, value);
    }
  }
  visit("", root);
  return output;
}
function mapToRows(input, entityId) {
  const result = [];
  for (const {key: rawKey, value: rawValue} of input) {
    const key = rawKey.toLowerCase();
    if (rawValue === void 0 || rawValue === null) {
      result.push({entity_id: entityId, key, value: null});
    } else {
      const value = String(rawValue).toLowerCase();
      if (key.length <= MAX_KEY_LENGTH && value.length <= MAX_VALUE_LENGTH) {
        result.push({entity_id: entityId, key, value});
      }
    }
  }
  return result;
}
function buildEntitySearch(entityId, entity) {
  const raw = traverse(entity);
  raw.push({key: "metadata.name", value: entity.metadata.name});
  raw.push({key: "metadata.namespace", value: entity.metadata.namespace});
  raw.push({key: "metadata.uid", value: entity.metadata.uid});
  if (!entity.metadata.namespace) {
    raw.push({key: "metadata.namespace", value: catalogModel.ENTITY_DEFAULT_NAMESPACE});
  }
  return mapToRows(raw, entityId);
}

const BATCH_SIZE$1 = 50;
class CommonDatabase {
  constructor(database, logger) {
    this.database = database;
    this.logger = logger;
  }
  async transaction(fn) {
    try {
      let result = void 0;
      await this.database.transaction(async (tx) => {
        result = await fn(tx);
      }, {
        doNotRejectOnRollback: true
      });
      return result;
    } catch (e) {
      this.logger.debug(`Error during transaction, ${e}`);
      if (/SQLITE_CONSTRAINT: UNIQUE/.test(e.message) || /unique constraint/.test(e.message)) {
        throw new errors.ConflictError(`Rejected due to a conflicting entity`, e);
      }
      throw e;
    }
  }
  async addEntities(txOpaque, request) {
    const tx = txOpaque;
    const result = [];
    const entityRows = [];
    const relationRows = [];
    const searchRows = [];
    for (const {entity, relations, locationId} of request) {
      if (entity.metadata.uid !== void 0) {
        throw new errors.InputError("May not specify uid for new entities");
      } else if (entity.metadata.etag !== void 0) {
        throw new errors.InputError("May not specify etag for new entities");
      } else if (entity.metadata.generation !== void 0) {
        throw new errors.InputError("May not specify generation for new entities");
      } else if (entity.relations !== void 0) {
        throw new errors.InputError("May not specify relations for new entities");
      }
      const uid = catalogModel.generateEntityUid();
      const etag = catalogModel.generateEntityEtag();
      const generation = 1;
      const newEntity = {
        ...entity,
        metadata: {
          ...entity.metadata,
          uid,
          etag,
          generation
        }
      };
      result.push({entity: newEntity, locationId});
      entityRows.push(this.toEntityRow(locationId, newEntity));
      relationRows.push(...this.toRelationRows(uid, relations));
      searchRows.push(...buildEntitySearch(uid, newEntity));
    }
    await tx.batchInsert("entities", entityRows, BATCH_SIZE$1);
    await tx.batchInsert("entities_relations", relationRows, BATCH_SIZE$1);
    await tx.batchInsert("entities_search", searchRows, BATCH_SIZE$1);
    return result;
  }
  async updateEntity(txOpaque, request, matchingEtag, matchingGeneration) {
    const tx = txOpaque;
    const {uid} = request.entity.metadata;
    if (!uid) {
      throw new errors.InputError("Must specify uid when updating entities");
    }
    const oldRows = await tx("entities").where({id: uid}).select();
    if (oldRows.length !== 1) {
      throw new errors.NotFoundError("No matching entity found");
    }
    const etag = oldRows[0].etag;
    const generation = Number(oldRows[0].generation);
    if (matchingEtag && matchingEtag !== etag) {
      throw new errors.ConflictError(`Etag mismatch, expected="${matchingEtag}" found="${etag}"`);
    }
    if (matchingGeneration && matchingGeneration !== generation) {
      throw new errors.ConflictError(`Generation mismatch, expected="${matchingGeneration}" found="${generation}"`);
    }
    const newRow = this.toEntityRow(request.locationId, request.entity);
    const updatedRows = await tx("entities").where({id: uid, etag}).update(newRow);
    if (updatedRows !== 1) {
      throw new errors.ConflictError(`Failed to update entity`);
    }
    const relationRows = this.toRelationRows(uid, request.relations);
    await tx("entities_relations").where({originating_entity_id: uid}).del();
    await tx.batchInsert("entities_relations", relationRows, BATCH_SIZE$1);
    try {
      const entries = buildEntitySearch(uid, request.entity);
      await tx("entities_search").where({entity_id: uid}).del();
      await tx.batchInsert("entities_search", entries, BATCH_SIZE$1);
    } catch {
    }
    return request;
  }
  async entities(txOpaque, request) {
    var _a, _b;
    const tx = txOpaque;
    let entitiesQuery = tx("entities");
    for (const singleFilter of (_b = (_a = request == null ? void 0 : request.filter) == null ? void 0 : _a.anyOf) != null ? _b : []) {
      entitiesQuery = entitiesQuery.orWhere(function singleFilterFn() {
        for (const {key, matchValueIn} of singleFilter.allOf) {
          const matchQuery = tx("entities_search").select("entity_id").where(function keyFilter() {
            this.andWhere({key: key.toLowerCase()});
            if (matchValueIn) {
              if (matchValueIn.length === 1) {
                this.andWhere({value: matchValueIn[0].toLowerCase()});
              } else if (matchValueIn.length > 1) {
                this.andWhere("value", "in", matchValueIn.map((v) => v.toLowerCase()));
              }
            }
          });
          this.andWhere("id", "in", matchQuery);
        }
      });
    }
    entitiesQuery = entitiesQuery.select("entities.*").orderBy("full_name", "asc");
    const {limit, offset} = parsePagination(request == null ? void 0 : request.pagination);
    if (limit !== void 0) {
      entitiesQuery = entitiesQuery.limit(limit + 1);
    }
    if (offset !== void 0) {
      entitiesQuery = entitiesQuery.offset(offset);
    }
    let rows = await entitiesQuery;
    let pageInfo;
    if (limit === void 0 || rows.length <= limit) {
      pageInfo = {hasNextPage: false};
    } else {
      rows = rows.slice(0, -1);
      pageInfo = {
        hasNextPage: true,
        endCursor: stringifyPagination({
          limit,
          offset: (offset != null ? offset : 0) + limit
        })
      };
    }
    return {
      entities: await this.toEntityResponses(tx, rows),
      pageInfo
    };
  }
  async entityByName(txOpaque, name) {
    const tx = txOpaque;
    const rows = await tx("entities").where({
      full_name: `${name.kind}:${name.namespace}/${name.name}`.toLowerCase()
    }).select();
    if (rows.length !== 1) {
      return void 0;
    }
    return this.toEntityResponses(tx, rows).then((r) => r[0]);
  }
  async entityByUid(txOpaque, uid) {
    const tx = txOpaque;
    const rows = await tx("entities").where({id: uid}).select();
    if (rows.length !== 1) {
      return void 0;
    }
    return this.toEntityResponses(tx, rows).then((r) => r[0]);
  }
  async removeEntityByUid(txOpaque, uid) {
    const tx = txOpaque;
    const result = await tx("entities").where({id: uid}).del();
    if (!result) {
      throw new errors.NotFoundError(`Found no entity with ID ${uid}`);
    }
  }
  async setRelations(txOpaque, originatingEntityId, relations) {
    const tx = txOpaque;
    const relationRows = this.toRelationRows(originatingEntityId, relations);
    await tx("entities_relations").where({originating_entity_id: originatingEntityId}).del();
    await tx.batchInsert("entities_relations", relationRows, BATCH_SIZE$1);
  }
  async addLocation(txOpaque, location) {
    const tx = txOpaque;
    const row = {
      id: location.id,
      type: location.type,
      target: location.target
    };
    await tx("locations").insert(row);
    return row;
  }
  async removeLocation(txOpaque, id) {
    const tx = txOpaque;
    const locations = await tx("locations").where({id}).select();
    if (!locations.length) {
      throw new errors.NotFoundError(`Found no location with ID ${id}`);
    }
    if (locations[0].type === "bootstrap") {
      throw new errors.ConflictError("You may not delete the bootstrap location.");
    }
    await tx("entities").where({location_id: id}).update({location_id: null});
    await tx("locations").where({id}).del();
  }
  async location(id) {
    const items = await this.database("locations").where("locations.id", id).leftOuterJoin("location_update_log_latest", "locations.id", "location_update_log_latest.location_id").select("locations.*", {
      status: "location_update_log_latest.status",
      timestamp: "location_update_log_latest.created_at",
      message: "location_update_log_latest.message"
    });
    if (!items.length) {
      throw new errors.NotFoundError(`Found no location with ID ${id}`);
    }
    return items[0];
  }
  async locations() {
    const locations = await this.database("locations").leftOuterJoin("location_update_log_latest", "locations.id", "location_update_log_latest.location_id").select("locations.*", {
      status: "location_update_log_latest.status",
      timestamp: "location_update_log_latest.created_at",
      message: "location_update_log_latest.message"
    });
    return locations;
  }
  async locationHistory(id) {
    const result = await this.database("location_update_log").where("location_id", id).orderBy("created_at", "desc").limit(10).select();
    return result;
  }
  async addLocationUpdateLogEvent(locationId, status, entityName, message) {
    const cutoff = new Date();
    cutoff.setDate(cutoff.getDate() - 1);
    await this.database("location_update_log").where("created_at", "<", cutoff.toISOString()).del();
    const items = [entityName].flat().map((n) => ({
      status,
      location_id: locationId,
      entity_name: n,
      message
    }));
    for (const chunk of lodash__default['default'].chunk(items, BATCH_SIZE$1)) {
      await this.database("location_update_log").insert(chunk);
    }
  }
  toEntityRow(locationId, entity) {
    const lowerKind = entity.kind.toLowerCase();
    const lowerNamespace = (entity.metadata.namespace || catalogModel.ENTITY_DEFAULT_NAMESPACE).toLowerCase();
    const lowerName = entity.metadata.name.toLowerCase();
    const data = {
      ...entity,
      metadata: lodash__default['default'].omit(entity.metadata, ...catalogModel.ENTITY_META_GENERATED_FIELDS)
    };
    return {
      id: entity.metadata.uid,
      location_id: locationId || null,
      etag: entity.metadata.etag,
      generation: entity.metadata.generation,
      full_name: `${lowerKind}:${lowerNamespace}/${lowerName}`,
      data: JSON.stringify(data)
    };
  }
  toRelationRows(originatingEntityId, relations) {
    const serializeName = (e) => `${e.kind}:${e.namespace}/${e.name}`.toLowerCase();
    const rows = relations.map(({source, target, type}) => ({
      originating_entity_id: originatingEntityId,
      source_full_name: serializeName(source),
      target_full_name: serializeName(target),
      type
    }));
    return deduplicateRelations(rows);
  }
  async toEntityResponses(tx, rows) {
    var _a;
    const relations = await this.getRelationsPerFullName(tx, rows.map((r) => r.full_name));
    const result = new Array();
    for (const row of rows) {
      const entity = JSON.parse(row.data);
      entity.metadata.uid = row.id;
      entity.metadata.etag = row.etag;
      entity.metadata.generation = Number(row.generation);
      entity.relations = ((_a = relations[row.full_name]) != null ? _a : []).map((r) => ({
        target: catalogModel.parseEntityName(r.target_full_name),
        type: r.type
      }));
      result.push({
        locationId: row.location_id || void 0,
        entity
      });
    }
    return result;
  }
  async getRelationsPerFullName(tx, sourceFullNames) {
    const batches = lodash__default['default'].chunk(lodash__default['default'].uniq(sourceFullNames), 500);
    const relations = new Array();
    for (const batch of batches) {
      relations.push(...await tx("entities_relations").whereIn("source_full_name", batch).orderBy(["type", "target_full_name"]).select());
    }
    return lodash__default['default'].groupBy(deduplicateRelations(relations), (r) => r.source_full_name);
  }
}
function parsePagination(input) {
  if (!input) {
    return {};
  }
  let {limit, offset} = input;
  if (input.after !== void 0) {
    let cursor;
    try {
      const json = Buffer.from(input.after, "base64").toString("utf8");
      cursor = JSON.parse(json);
    } catch {
      throw new errors.InputError("Malformed after cursor, could not be parsed");
    }
    if (cursor.limit !== void 0) {
      if (!Number.isInteger(cursor.limit)) {
        throw new errors.InputError("Malformed after cursor, limit was not an number");
      }
      limit = cursor.limit;
    }
    if (cursor.offset !== void 0) {
      if (!Number.isInteger(cursor.offset)) {
        throw new errors.InputError("Malformed after cursor, offset was not a number");
      }
      offset = cursor.offset;
    }
  }
  return {limit, offset};
}
function stringifyPagination(input) {
  const json = JSON.stringify({limit: input.limit, offset: input.offset});
  const base64 = Buffer.from(json, "utf8").toString("base64");
  return base64;
}
function deduplicateRelations(rows) {
  return lodash__default['default'].uniqBy(rows, (r) => `${r.source_full_name}:${r.target_full_name}:${r.type}`);
}

const migrationsDir = backendCommon.resolvePackagePath("@backstage/plugin-catalog-backend", "migrations");
const defaultOptions = {
  logger: backendCommon.getVoidLogger()
};
class DatabaseManager {
  static async createDatabase(knex, options = {}) {
    await knex.migrate.latest({
      directory: migrationsDir
    });
    const {logger} = {...defaultOptions, ...options};
    return new CommonDatabase(knex, logger);
  }
  static async createInMemoryDatabase() {
    const knex = await this.createInMemoryDatabaseConnection();
    return await this.createDatabase(knex);
  }
  static async createInMemoryDatabaseConnection() {
    const knex = knexFactory__default['default']({
      client: "sqlite3",
      connection: ":memory:",
      useNullAsDefault: true
    });
    knex.client.pool.on("createSuccess", (_eventId, resource) => {
      resource.run("PRAGMA foreign_keys = ON", () => {
      });
    });
    return knex;
  }
  static async createTestDatabase() {
    const knex = await this.createTestDatabaseConnection();
    return await this.createDatabase(knex);
  }
  static async createTestDatabaseConnection() {
    const config = {
      client: "sqlite3",
      connection: ":memory:",
      useNullAsDefault: true
    };
    let knex = knexFactory__default['default'](config);
    if (typeof config.connection !== "string") {
      const tempDbName = `d${uuid.v4().replace(/-/g, "")}`;
      await knex.raw(`CREATE DATABASE ${tempDbName};`);
      knex = knexFactory__default['default']({
        ...config,
        connection: {
          ...config.connection,
          database: tempDbName
        }
      });
    }
    knex.client.pool.on("createSuccess", (_eventId, resource) => {
      resource.run("PRAGMA foreign_keys = ON", () => {
      });
    });
    return knex;
  }
}

function runPeriodically(fn, delayMs) {
  let cancel;
  let cancelled = false;
  const cancellationPromise = new Promise((resolve) => {
    cancel = () => {
      resolve();
      cancelled = true;
    };
  });
  const startRefresh = async () => {
    while (!cancelled) {
      try {
        await fn();
      } catch {
      }
      await Promise.race([
        new Promise((resolve) => setTimeout(resolve, delayMs)),
        cancellationPromise
      ]);
    }
  };
  startRefresh();
  return cancel;
}

class HigherOrderOperations {
  constructor(entitiesCatalog, locationsCatalog, locationReader, logger) {
    this.entitiesCatalog = entitiesCatalog;
    this.locationsCatalog = locationsCatalog;
    this.locationReader = locationReader;
    this.logger = logger;
  }
  async addLocation(spec, options) {
    const dryRun = (options == null ? void 0 : options.dryRun) || false;
    const previousLocations = await this.locationsCatalog.locations();
    const previousLocation = previousLocations.find((l) => spec.type === l.data.type && spec.target === l.data.target);
    const location = previousLocation ? previousLocation.data : {
      id: uuid.v4(),
      type: spec.type,
      target: spec.target
    };
    const readerOutput = await this.locationReader.read(spec);
    if (!(spec.presence === "optional") && readerOutput.errors.length) {
      const item = readerOutput.errors[0];
      throw item.error;
    }
    if (!previousLocation && !dryRun) {
      await this.locationsCatalog.addLocation(location);
    }
    if (readerOutput.entities.length === 0) {
      return {location, entities: []};
    }
    const writtenEntities = await this.entitiesCatalog.batchAddOrUpdateEntities(readerOutput.entities, {
      locationId: dryRun ? void 0 : location.id,
      dryRun,
      outputEntities: true
    });
    const entities = writtenEntities.map((e) => e.entity);
    return {location, entities};
  }
  async refreshAllLocations() {
    const startTimestamp = process.hrtime();
    const logger = this.logger.child({
      component: "catalog-all-locations-refresh"
    });
    logger.info("Locations Refresh: Beginning locations refresh");
    const locations = await this.locationsCatalog.locations();
    logger.info(`Locations Refresh: Visiting ${locations.length} locations`);
    for (const {data: location} of locations) {
      logger.info(`Locations Refresh: Refreshing location ${catalogModel.stringifyLocationReference(location)}`);
      try {
        await this.refreshSingleLocation(location, logger);
        await this.locationsCatalog.logUpdateSuccess(location.id, void 0);
      } catch (e) {
        logger.warn(`Locations Refresh: Failed to refresh location ${catalogModel.stringifyLocationReference(location)}, ${e.stack}`);
        await this.locationsCatalog.logUpdateFailure(location.id, e);
      }
    }
    logger.info(`Locations Refresh: Completed locations refresh in ${durationText(startTimestamp)}`);
  }
  async refreshSingleLocation(location, optionalLogger) {
    let startTimestamp = process.hrtime();
    const logger = optionalLogger || this.logger;
    const readerOutput = await this.locationReader.read({
      type: location.type,
      target: location.target
    });
    for (const item of readerOutput.errors) {
      logger.warn(`Failed item in location ${catalogModel.stringifyLocationReference(item.location)}, ${item.error.stack}`);
    }
    logger.info(`Read ${readerOutput.entities.length} entities from location ${catalogModel.stringifyLocationReference(location)} in ${durationText(startTimestamp)}`);
    startTimestamp = process.hrtime();
    try {
      await this.entitiesCatalog.batchAddOrUpdateEntities(readerOutput.entities, {locationId: location.id});
    } catch (e) {
      for (const entity of readerOutput.entities) {
        await this.locationsCatalog.logUpdateFailure(location.id, e, entity.entity.metadata.name);
      }
      throw e;
    }
    logger.debug(`Posting update success markers`);
    await this.locationsCatalog.logUpdateSuccess(location.id, readerOutput.entities.map((e) => e.entity.metadata.name));
    logger.info(`Wrote ${readerOutput.entities.length} entities from location ${catalogModel.stringifyLocationReference(location)} in ${durationText(startTimestamp)}`);
  }
}

function notFoundError(atLocation, message) {
  return {
    type: "error",
    location: atLocation,
    error: new errors.NotFoundError(message)
  };
}
function inputError(atLocation, message) {
  return {
    type: "error",
    location: atLocation,
    error: new errors.InputError(message)
  };
}
function generalError(atLocation, message) {
  return {type: "error", location: atLocation, error: new Error(message)};
}
function location(newLocation, optional) {
  return {type: "location", location: newLocation, optional};
}
function entity(atLocation, newEntity) {
  return {type: "entity", location: atLocation, entity: newEntity};
}
function relation(spec) {
  return {type: "relation", relation: spec};
}

var results = /*#__PURE__*/Object.freeze({
  __proto__: null,
  notFoundError: notFoundError,
  inputError: inputError,
  generalError: generalError,
  location: location,
  entity: entity,
  relation: relation
});

const MAX_DEPTH = 10;
class LocationReaders {
  constructor(options) {
    this.options = options;
  }
  async read(location$1) {
    const {rulesEnforcer, logger} = this.options;
    const output = {
      entities: [],
      errors: []
    };
    let items = [location(location$1, false)];
    for (let depth = 0; depth < MAX_DEPTH; ++depth) {
      const newItems = [];
      const emit = (i) => newItems.push(i);
      for (const item of items) {
        if (item.type === "location") {
          await this.handleLocation(item, emit);
        } else if (item.type === "entity") {
          if (rulesEnforcer.isAllowed(item.entity, item.location)) {
            const relations = Array();
            const entity = await this.handleEntity(item, (emitResult) => {
              if (emitResult.type === "relation") {
                relations.push(emitResult.relation);
                return;
              }
              emit(emitResult);
            }, location$1);
            if (entity) {
              output.entities.push({
                entity,
                location: item.location,
                relations
              });
            }
          } else {
            output.errors.push({
              location: item.location,
              error: new errors.NotAllowedError(`Entity of kind ${item.entity.kind} is not allowed from location ${catalogModel.stringifyLocationReference(item.location)}`)
            });
          }
        } else if (item.type === "error") {
          await this.handleError(item, emit);
          output.errors.push({
            location: item.location,
            error: item.error
          });
        }
      }
      if (newItems.length === 0) {
        return output;
      }
      items = newItems;
    }
    const message = `Max recursion depth ${MAX_DEPTH} reached for location ${location$1.type} ${location$1.target}`;
    logger.warn(message);
    output.errors.push({location: location$1, error: new Error(message)});
    return output;
  }
  async handleLocation(item, emit) {
    const {processors, logger} = this.options;
    const validatedEmit = (emitResult) => {
      if (emitResult.type === "relation") {
        throw new Error("readLocation may not emit entity relations");
      }
      if (emitResult.type === "location" && emitResult.location.type === item.location.type && emitResult.location.target === item.location.target) {
        return;
      }
      emit(emitResult);
    };
    for (const processor of processors) {
      if (processor.readLocation) {
        try {
          if (await processor.readLocation(item.location, item.optional, validatedEmit, this.options.parser)) {
            return;
          }
        } catch (e) {
          const message2 = `Processor ${processor.constructor.name} threw an error while reading location ${catalogModel.stringifyLocationReference(item.location)}, ${e}`;
          emit(generalError(item.location, message2));
          logger.warn(message2);
        }
      }
    }
    const message = `No processor was able to read location ${catalogModel.stringifyLocationReference(item.location)}`;
    emit(inputError(item.location, message));
    logger.warn(message);
  }
  async handleEntity(item, emit, originLocation) {
    var _a;
    const {processors, logger} = this.options;
    let current = item.entity;
    const kind = current.kind || "";
    const namespace = !current.metadata ? "" : (_a = current.metadata.namespace) != null ? _a : catalogModel.ENTITY_DEFAULT_NAMESPACE;
    const name = !current.metadata ? "" : current.metadata.name;
    for (const processor of processors) {
      if (processor.preProcessEntity) {
        try {
          current = await processor.preProcessEntity(current, item.location, emit, originLocation);
        } catch (e) {
          const message = `Processor ${processor.constructor.name} threw an error while preprocessing entity ${kind}:${namespace}/${name} at ${catalogModel.stringifyLocationReference(item.location)}, ${e}`;
          emit(generalError(item.location, e.message));
          logger.warn(message);
          return void 0;
        }
      }
    }
    try {
      const next = await this.options.policy.enforce(current);
      if (!next) {
        const message = `Policy unexpectedly returned no data while analyzing entity ${kind}:${namespace}/${name} at ${catalogModel.stringifyLocationReference(item.location)}`;
        emit(generalError(item.location, message));
        logger.warn(message);
        return void 0;
      }
      current = next;
    } catch (e) {
      const message = `Policy check failed while analyzing entity ${kind}:${namespace}/${name} at ${catalogModel.stringifyLocationReference(item.location)}, ${e}`;
      emit(inputError(item.location, e.message));
      logger.warn(message);
      return void 0;
    }
    let handled = false;
    for (const processor of processors) {
      if (processor.validateEntityKind) {
        try {
          handled = await processor.validateEntityKind(current);
          if (handled) {
            break;
          }
        } catch (e) {
          const message = `Processor ${processor.constructor.name} threw an error while validating the entity ${kind}:${namespace}/${name} at ${catalogModel.stringifyLocationReference(item.location)}, ${e}`;
          emit(inputError(item.location, message));
          logger.warn(message);
          return void 0;
        }
      }
    }
    if (!handled) {
      const message = `No processor recognized the entity ${kind}:${namespace}/${name} at ${catalogModel.stringifyLocationReference(item.location)}`;
      emit(inputError(item.location, message));
      logger.warn(message);
      return void 0;
    }
    for (const processor of processors) {
      if (processor.postProcessEntity) {
        try {
          current = await processor.postProcessEntity(current, item.location, emit);
        } catch (e) {
          const message = `Processor ${processor.constructor.name} threw an error while postprocessing entity ${kind}:${namespace}/${name} at ${catalogModel.stringifyLocationReference(item.location)}, ${e}`;
          emit(generalError(item.location, message));
          logger.warn(message);
          return void 0;
        }
      }
    }
    return current;
  }
  async handleError(item, emit) {
    const {processors, logger} = this.options;
    logger.debug(`Encountered error at location ${catalogModel.stringifyLocationReference(item.location)}, ${item.error}`);
    const validatedEmit = (emitResult) => {
      if (emitResult.type === "relation") {
        throw new Error("handleError may not emit entity relations");
      }
      emit(emitResult);
    };
    for (const processor of processors) {
      if (processor.handleError) {
        try {
          await processor.handleError(item.error, item.location, validatedEmit);
        } catch (e) {
          const message = `Processor ${processor.constructor.name} threw an error while handling another error at ${catalogModel.stringifyLocationReference(item.location)}, ${e}`;
          emit(generalError(item.location, message));
          logger.warn(message);
        }
      }
    }
  }
}

class AnnotateLocationEntityProcessor {
  constructor(options) {
    this.options = options;
  }
  async preProcessEntity(entity, location, _, originLocation) {
    const {integrations} = this.options;
    let viewUrl;
    let editUrl;
    let sourceLocation;
    if (location.type === "url") {
      const scmIntegration = integrations.byUrl(location.target);
      viewUrl = location.target;
      editUrl = scmIntegration == null ? void 0 : scmIntegration.resolveEditUrl(location.target);
      const sourceUrl = scmIntegration == null ? void 0 : scmIntegration.resolveUrl({
        url: "./",
        base: location.target
      });
      if (sourceUrl) {
        sourceLocation = catalogModel.stringifyLocationReference({
          type: "url",
          target: sourceUrl
        });
      }
    }
    return lodash.merge({
      metadata: {
        annotations: lodash.pickBy({
          [catalogModel.LOCATION_ANNOTATION]: catalogModel.stringifyLocationReference(location),
          [catalogModel.ORIGIN_LOCATION_ANNOTATION]: catalogModel.stringifyLocationReference(originLocation),
          [catalogModel.VIEW_URL_ANNOTATION]: viewUrl,
          [catalogModel.EDIT_URL_ANNOTATION]: editUrl,
          [catalogModel.SOURCE_LOCATION_ANNOTATION]: sourceLocation
        }, lodash.identity)
      }
    }, entity);
  }
}

const GITHUB_ACTIONS_ANNOTATION = "github.com/project-slug";
class AnnotateScmSlugEntityProcessor {
  constructor(opts) {
    this.opts = opts;
  }
  static fromConfig(config) {
    return new AnnotateScmSlugEntityProcessor({
      scmIntegrationRegistry: integration.ScmIntegrations.fromConfig(config)
    });
  }
  async preProcessEntity(entity, location) {
    var _a;
    if (entity.kind !== "Component" || location.type !== "url") {
      return entity;
    }
    const scmIntegration = this.opts.scmIntegrationRegistry.byUrl(location.target);
    if (!scmIntegration || scmIntegration.type !== "github") {
      return entity;
    }
    const gitUrl = parseGitUrl__default['default'](location.target);
    let githubProjectSlug = (_a = entity.metadata.annotations) == null ? void 0 : _a[GITHUB_ACTIONS_ANNOTATION];
    if (!githubProjectSlug) {
      githubProjectSlug = `${gitUrl.owner}/${gitUrl.name}`;
    }
    return lodash.merge({
      metadata: {
        annotations: lodash.pickBy({
          [GITHUB_ACTIONS_ANNOTATION]: githubProjectSlug
        }, lodash.identity)
      }
    }, entity);
  }
}

function readAwsOrganizationConfig(config) {
  const providerConfig = config.getOptionalConfig("provider");
  const roleArn = providerConfig == null ? void 0 : providerConfig.getOptionalString("roleArn");
  return {
    roleArn
  };
}

const AWS_ORGANIZATION_REGION = "us-east-1";
const LOCATION_TYPE = "aws-cloud-accounts";
const ACCOUNTID_ANNOTATION = "amazonaws.com/account-id";
const ARN_ANNOTATION = "amazonaws.com/arn";
const ORGANIZATION_ANNOTATION = "amazonaws.com/organization-id";
class AwsOrganizationCloudAccountProcessor {
  static fromConfig(config, options) {
    const c = config.getOptionalConfig("catalog.processors.awsOrganization");
    return new AwsOrganizationCloudAccountProcessor({
      ...options,
      provider: c ? readAwsOrganizationConfig(c) : {}
    });
  }
  static buildCredentials(config) {
    const roleArn = config.roleArn;
    if (!roleArn) {
      return void 0;
    }
    return new AWS__default['default'].ChainableTemporaryCredentials({
      params: {
        RoleSessionName: "backstage-aws-organization-processor",
        RoleArn: roleArn
      }
    });
  }
  constructor(options) {
    this.provider = options.provider;
    this.logger = options.logger;
    const credentials = AwsOrganizationCloudAccountProcessor.buildCredentials(this.provider);
    this.organizations = new AWS__default['default'].Organizations({
      credentials,
      region: AWS_ORGANIZATION_REGION
    });
  }
  normalizeName(name) {
    return name.trim().toLocaleLowerCase().replace(/[^a-zA-Z0-9\-]/g, "-");
  }
  extractInformationFromArn(arn) {
    const parts = arn.split("/");
    return {
      accountId: parts[parts.length - 1],
      organizationId: parts[parts.length - 2]
    };
  }
  async getAwsAccounts() {
    let awsAccounts = [];
    let isInitialAttempt = true;
    let nextToken = void 0;
    while (isInitialAttempt || nextToken) {
      isInitialAttempt = false;
      const orgAccounts = await this.organizations.listAccounts({NextToken: nextToken}).promise();
      if (orgAccounts.Accounts) {
        awsAccounts = awsAccounts.concat(orgAccounts.Accounts);
      }
      nextToken = orgAccounts.NextToken;
    }
    return awsAccounts;
  }
  mapAccountToComponent(account) {
    const {accountId, organizationId} = this.extractInformationFromArn(account.Arn);
    return {
      apiVersion: "backstage.io/v1alpha1",
      kind: "Resource",
      metadata: {
        annotations: {
          [ACCOUNTID_ANNOTATION]: accountId,
          [ARN_ANNOTATION]: account.Arn || "",
          [ORGANIZATION_ANNOTATION]: organizationId
        },
        name: this.normalizeName(account.Name || ""),
        namespace: "default"
      },
      spec: {
        type: "cloud-account",
        owner: "unknown"
      }
    };
  }
  async readLocation(location, _optional, emit) {
    if (location.type !== LOCATION_TYPE) {
      return false;
    }
    (await this.getAwsAccounts()).map((account) => this.mapAccountToComponent(account)).filter((entity) => {
      if (location.target !== "") {
        if (entity.metadata.annotations) {
          return entity.metadata.annotations[ORGANIZATION_ANNOTATION] === location.target;
        }
        return false;
      }
      return true;
    }).forEach((entity$1) => {
      emit(entity(location, entity$1));
    });
    return true;
  }
}

class BitbucketClient {
  constructor(options) {
    this.config = options.config;
  }
  async listProjects(options) {
    return this.pagedRequest(`${this.config.apiBaseUrl}/projects`, options);
  }
  async listRepositories(projectKey, options) {
    return this.pagedRequest(`${this.config.apiBaseUrl}/projects/${projectKey}/repos`, options);
  }
  async pagedRequest(endpoint, options) {
    const request = new URL(endpoint);
    for (const key in options) {
      if (options[key]) {
        request.searchParams.append(key, options[key].toString());
      }
    }
    const response = await fetch__default['default'](request.toString(), integration.getBitbucketRequestOptions(this.config));
    if (!response.ok) {
      throw new Error(`Unexpected response when fetching ${request.toString()}. Expected 200 but got ${response.status} - ${response.statusText}`);
    }
    return response.json().then((repositories) => {
      return repositories;
    });
  }
}
async function* paginated(request, options) {
  const opts = options || {start: 0};
  let res;
  do {
    res = await request(opts);
    opts.start = res.nextPageStart;
    for (const item of res.values) {
      yield item;
    }
  } while (!res.isLastPage);
}

const defaultRepositoryParser = async function* defaultRepositoryParser2({
  target
}) {
  yield location({
    type: "url",
    target
  }, true);
};

class BitbucketDiscoveryProcessor {
  static fromConfig(config, options) {
    const integrations = integration.ScmIntegrations.fromConfig(config);
    return new BitbucketDiscoveryProcessor({
      ...options,
      integrations
    });
  }
  constructor(options) {
    this.integrations = options.integrations;
    this.parser = options.parser || defaultRepositoryParser;
    this.logger = options.logger;
  }
  async readLocation(location, _optional, emit) {
    if (location.type !== "bitbucket-discovery") {
      return false;
    }
    const integration = this.integrations.bitbucket.byUrl(location.target);
    if (!integration) {
      throw new Error(`There is no Bitbucket integration that matches ${location.target}. Please add a configuration entry for it under integrations.bitbucket`);
    } else if (integration.config.host === "bitbucket.org") {
      throw new Error(`Component discovery for Bitbucket Cloud is not yet supported`);
    }
    const client = new BitbucketClient({
      config: integration.config
    });
    const startTimestamp = Date.now();
    this.logger.info(`Reading Bitbucket repositories from ${location.target}`);
    const {catalogPath} = parseUrl(location.target);
    const result = await readBitbucketOrg(client, location.target);
    for (const repository of result.matches) {
      for await (const entity of this.parser({
        integration,
        target: `${repository.links.self[0].href}${catalogPath}`,
        logger: this.logger
      })) {
        emit(entity);
      }
    }
    const duration = ((Date.now() - startTimestamp) / 1e3).toFixed(1);
    this.logger.debug(`Read ${result.scanned} Bitbucket repositories (${result.matches.length} matching the pattern) in ${duration} seconds`);
    return true;
  }
}
async function readBitbucketOrg(client, target) {
  const {projectSearchPath, repoSearchPath} = parseUrl(target);
  const projects = paginated((options) => client.listProjects(options));
  const result = {
    scanned: 0,
    matches: []
  };
  for await (const project of projects) {
    if (!projectSearchPath.test(project.key)) {
      continue;
    }
    const repositories = paginated((options) => client.listRepositories(project.key, options));
    for await (const repository of repositories) {
      result.scanned++;
      if (repoSearchPath.test(repository.slug)) {
        result.matches.push(repository);
      }
    }
  }
  return result;
}
function parseUrl(urlString) {
  const url = new URL(urlString);
  const path = url.pathname.substr(1).split("/");
  if (path.length > 3 && path[1].length && path[3].length) {
    return {
      projectSearchPath: escapeRegExp(decodeURIComponent(path[1])),
      repoSearchPath: escapeRegExp(decodeURIComponent(path[3])),
      catalogPath: `/${decodeURIComponent(path.slice(4).join("/"))}`
    };
  }
  throw new Error(`Failed to parse ${urlString}`);
}
function escapeRegExp(str) {
  return new RegExp(`^${str.replace(/\*/g, ".*")}$`);
}

class BuiltinKindsEntityProcessor {
  constructor() {
    this.validators = [
      catalogModel.apiEntityV1alpha1Validator,
      catalogModel.componentEntityV1alpha1Validator,
      catalogModel.resourceEntityV1alpha1Validator,
      catalogModel.groupEntityV1alpha1Validator,
      catalogModel.locationEntityV1alpha1Validator,
      catalogModel.templateEntityV1alpha1Validator,
      catalogModel.templateEntityV1beta2Validator,
      catalogModel.userEntityV1alpha1Validator,
      catalogModel.systemEntityV1alpha1Validator,
      catalogModel.domainEntityV1alpha1Validator
    ];
  }
  async validateEntityKind(entity) {
    for (const validator of this.validators) {
      const results = await validator.check(entity);
      if (results) {
        return true;
      }
    }
    return false;
  }
  async postProcessEntity(entity, _location, emit) {
    const selfRef = catalogModel.getEntityName(entity);
    function doEmit(targets, context, outgoingRelation, incomingRelation) {
      if (!targets) {
        return;
      }
      for (const target of [targets].flat()) {
        const targetRef = catalogModel.parseEntityRef(target, context);
        if (targetRef.kind === void 0) {
          throw new Error(`Entity reference "${target}" did not specify a kind (e.g. starting with "Component:"), and has no default`);
        }
        emit(relation({
          source: selfRef,
          type: outgoingRelation,
          target: {
            kind: targetRef.kind,
            namespace: targetRef.namespace,
            name: targetRef.name
          }
        }));
        emit(relation({
          source: {
            kind: targetRef.kind,
            namespace: targetRef.namespace,
            name: targetRef.name
          },
          type: incomingRelation,
          target: selfRef
        }));
      }
    }
    if (entity.kind === "Template") {
      const template = entity;
      doEmit(template.spec.owner, {defaultKind: "Group", defaultNamespace: selfRef.namespace}, catalogModel.RELATION_OWNED_BY, catalogModel.RELATION_OWNER_OF);
    }
    if (entity.kind === "Component") {
      const component = entity;
      doEmit(component.spec.owner, {defaultKind: "Group", defaultNamespace: selfRef.namespace}, catalogModel.RELATION_OWNED_BY, catalogModel.RELATION_OWNER_OF);
      doEmit(component.spec.subcomponentOf, {defaultKind: "Component", defaultNamespace: selfRef.namespace}, catalogModel.RELATION_PART_OF, catalogModel.RELATION_HAS_PART);
      doEmit(component.spec.providesApis, {defaultKind: "API", defaultNamespace: selfRef.namespace}, catalogModel.RELATION_PROVIDES_API, catalogModel.RELATION_API_PROVIDED_BY);
      doEmit(component.spec.consumesApis, {defaultKind: "API", defaultNamespace: selfRef.namespace}, catalogModel.RELATION_CONSUMES_API, catalogModel.RELATION_API_CONSUMED_BY);
      doEmit(component.spec.dependsOn, {defaultNamespace: selfRef.namespace}, catalogModel.RELATION_DEPENDS_ON, catalogModel.RELATION_DEPENDENCY_OF);
      doEmit(component.spec.system, {defaultKind: "System", defaultNamespace: selfRef.namespace}, catalogModel.RELATION_PART_OF, catalogModel.RELATION_HAS_PART);
    }
    if (entity.kind === "API") {
      const api = entity;
      doEmit(api.spec.owner, {defaultKind: "Group", defaultNamespace: selfRef.namespace}, catalogModel.RELATION_OWNED_BY, catalogModel.RELATION_OWNER_OF);
      doEmit(api.spec.system, {defaultKind: "System", defaultNamespace: selfRef.namespace}, catalogModel.RELATION_PART_OF, catalogModel.RELATION_HAS_PART);
    }
    if (entity.kind === "Resource") {
      const resource = entity;
      doEmit(resource.spec.owner, {defaultKind: "Group", defaultNamespace: selfRef.namespace}, catalogModel.RELATION_OWNED_BY, catalogModel.RELATION_OWNER_OF);
      doEmit(resource.spec.dependsOn, {defaultNamespace: selfRef.namespace}, catalogModel.RELATION_DEPENDS_ON, catalogModel.RELATION_DEPENDENCY_OF);
      doEmit(resource.spec.system, {defaultKind: "System", defaultNamespace: selfRef.namespace}, catalogModel.RELATION_PART_OF, catalogModel.RELATION_HAS_PART);
    }
    if (entity.kind === "User") {
      const user = entity;
      doEmit(user.spec.memberOf, {defaultKind: "Group", defaultNamespace: selfRef.namespace}, catalogModel.RELATION_MEMBER_OF, catalogModel.RELATION_HAS_MEMBER);
    }
    if (entity.kind === "Group") {
      const group = entity;
      doEmit(group.spec.parent, {defaultKind: "Group", defaultNamespace: selfRef.namespace}, catalogModel.RELATION_CHILD_OF, catalogModel.RELATION_PARENT_OF);
      doEmit(group.spec.children, {defaultKind: "Group", defaultNamespace: selfRef.namespace}, catalogModel.RELATION_PARENT_OF, catalogModel.RELATION_CHILD_OF);
      doEmit(group.spec.members, {defaultKind: "User", defaultNamespace: selfRef.namespace}, catalogModel.RELATION_HAS_MEMBER, catalogModel.RELATION_MEMBER_OF);
    }
    if (entity.kind === "System") {
      const system = entity;
      doEmit(system.spec.owner, {defaultKind: "Group", defaultNamespace: selfRef.namespace}, catalogModel.RELATION_OWNED_BY, catalogModel.RELATION_OWNER_OF);
      doEmit(system.spec.domain, {defaultKind: "Domain", defaultNamespace: selfRef.namespace}, catalogModel.RELATION_PART_OF, catalogModel.RELATION_HAS_PART);
    }
    if (entity.kind === "Domain") {
      const domain = entity;
      doEmit(domain.spec.owner, {defaultKind: "Group", defaultNamespace: selfRef.namespace}, catalogModel.RELATION_OWNED_BY, catalogModel.RELATION_OWNER_OF);
    }
    return entity;
  }
}

function resolveCodeOwner(contents, pattern = "*") {
  const owners = codeowners.parse(contents);
  return fp.pipe(fp.filter((e) => e.pattern === pattern), fp.reverse, fp.head, fp.get("owners"), fp.head, normalizeCodeOwner)(owners);
}
function normalizeCodeOwner(owner) {
  if (owner.match(/^@.*\/.*/)) {
    return owner.split("/")[1];
  } else if (owner.match(/^@.*/)) {
    return owner.substring(1);
  } else if (owner.match(/^.*@.*\..*$/)) {
    return owner.split("@")[0];
  }
  return owner;
}

const CODEOWNERS = "CODEOWNERS";
const scmCodeOwnersPaths = {
  bitbucket: [CODEOWNERS, `.bitbucket/${CODEOWNERS}`],
  gitlab: [CODEOWNERS, `.gitlab/${CODEOWNERS}`, `docs/${CODEOWNERS}`],
  github: [CODEOWNERS, `.github/${CODEOWNERS}`, `docs/${CODEOWNERS}`]
};

async function readCodeOwners(reader, sourceUrl, codeownersPaths) {
  const readOwnerLocation = async (path) => {
    const url = `${sourceUrl}${path}`;
    const data = await reader.read(url);
    return data.toString();
  };
  const candidates = codeownersPaths.map(readOwnerLocation);
  return Promise.any(candidates).catch((aggregateError) => {
    const hardError = aggregateError.errors.find((error) => !(error instanceof errors.NotFoundError));
    if (hardError) {
      throw hardError;
    }
    return void 0;
  });
}
async function findCodeOwnerByTarget(reader, targetUrl, scmIntegration) {
  var _a;
  const codeownersPaths = scmCodeOwnersPaths[(_a = scmIntegration == null ? void 0 : scmIntegration.type) != null ? _a : ""];
  const sourceUrl = scmIntegration == null ? void 0 : scmIntegration.resolveUrl({
    url: "/",
    base: targetUrl
  });
  if (!sourceUrl || !codeownersPaths) {
    return void 0;
  }
  const contents = await readCodeOwners(reader, sourceUrl, codeownersPaths);
  if (!contents) {
    return void 0;
  }
  const owner = resolveCodeOwner(contents);
  return owner;
}

const ALLOWED_KINDS = ["API", "Component", "Domain", "Resource", "System"];
const ALLOWED_LOCATION_TYPES = [
  "url",
  "azure/api",
  "bitbucket/api",
  "github",
  "github/api",
  "gitlab",
  "gitlab/api"
];
class CodeOwnersProcessor {
  static fromConfig(config, options) {
    const integrations = integration.ScmIntegrations.fromConfig(config);
    return new CodeOwnersProcessor({
      ...options,
      integrations
    });
  }
  constructor(options) {
    this.integrations = options.integrations;
    this.logger = options.logger;
    this.reader = options.reader;
  }
  async preProcessEntity(entity, location) {
    if (!entity || !ALLOWED_KINDS.includes(entity.kind) || !ALLOWED_LOCATION_TYPES.includes(location.type) || entity.spec && entity.spec.owner) {
      return entity;
    }
    const scmIntegration = this.integrations.byUrl(location.target);
    if (!scmIntegration) {
      return entity;
    }
    const owner = await findCodeOwnerByTarget(this.reader, location.target, scmIntegration);
    if (!owner) {
      this.logger.debug(`CodeOwnerProcessor could not resolve owner for ${location.target}`);
      return entity;
    }
    return {
      ...entity,
      spec: {...entity.spec, owner}
    };
  }
}

function* parseEntityYaml(data, location) {
  var _a;
  let documents;
  try {
    documents = yaml__default['default'].parseAllDocuments(data.toString("utf8")).filter((d) => d);
  } catch (e) {
    const loc = catalogModel.stringifyLocationReference(location);
    const message = `Failed to parse YAML at ${loc}, ${e}`;
    yield generalError(location, message);
    return;
  }
  for (const document of documents) {
    if ((_a = document.errors) == null ? void 0 : _a.length) {
      const loc = catalogModel.stringifyLocationReference(location);
      const message = `YAML error at ${loc}, ${document.errors[0]}`;
      yield generalError(location, message);
    } else {
      const json = document.toJSON();
      if (lodash__default['default'].isPlainObject(json)) {
        yield entity(location, json);
      } else if (json === null) ; else {
        const message = `Expected object at root, got ${typeof json}`;
        yield generalError(location, message);
      }
    }
  }
}
const defaultEntityDataParser = async function* defaultEntityDataParser2({
  data,
  location
}) {
  for (const e of parseEntityYaml(data, location)) {
    yield e;
  }
};

const glob = util.promisify(g__default['default']);
class FileReaderProcessor {
  async readLocation(location, optional, emit) {
    if (location.type !== "file") {
      return false;
    }
    try {
      const fileMatches = await glob(location.target);
      if (fileMatches.length > 0) {
        for (const fileMatch of fileMatches) {
          const data = await fs__default['default'].readFile(fileMatch);
          for (const parseResult of parseEntityYaml(data, {
            type: "file",
            target: path__default['default'].normalize(fileMatch)
          })) {
            emit(parseResult);
          }
        }
      } else if (!optional) {
        const message = `${location.type} ${location.target} does not exist`;
        emit(notFoundError(location, message));
      }
    } catch (e) {
      const message = `${location.type} ${location.target} could not be read, ${e}`;
      emit(generalError(location, message));
    }
    return true;
  }
}

function readGithubConfig(config) {
  var _a;
  const providers = [];
  const providerConfigs = (_a = config.getOptionalConfigArray("catalog.processors.githubOrg.providers")) != null ? _a : [];
  for (const providerConfig of providerConfigs) {
    const target = providerConfig.getString("target").replace(/\/+$/, "");
    let apiBaseUrl = providerConfig.getOptionalString("apiBaseUrl");
    const token = providerConfig.getOptionalString("token");
    if (apiBaseUrl) {
      apiBaseUrl = apiBaseUrl.replace(/\/+$/, "");
    } else if (target === "https://github.com") {
      apiBaseUrl = "https://api.github.com";
    }
    if (!apiBaseUrl) {
      throw new Error(`Provider at ${target} must configure an explicit apiBaseUrl`);
    }
    providers.push({target, apiBaseUrl, token});
  }
  if (!providers.some((p) => p.target === "https://github.com")) {
    providers.push({
      target: "https://github.com",
      apiBaseUrl: "https://api.github.com"
    });
  }
  return providers;
}

async function getOrganizationUsers(client, org) {
  const query = `
    query users($org: String!, $cursor: String) {
      organization(login: $org) {
        membersWithRole(first: 100, after: $cursor) {
          pageInfo { hasNextPage, endCursor }
          nodes { avatarUrl, bio, email, login, name }
        }
      }
    }`;
  const mapper = (user) => {
    const entity = {
      apiVersion: "backstage.io/v1alpha1",
      kind: "User",
      metadata: {
        name: user.login,
        annotations: {
          "github.com/user-login": user.login
        }
      },
      spec: {
        profile: {},
        memberOf: []
      }
    };
    if (user.bio)
      entity.metadata.description = user.bio;
    if (user.name)
      entity.spec.profile.displayName = user.name;
    if (user.email)
      entity.spec.profile.email = user.email;
    if (user.avatarUrl)
      entity.spec.profile.picture = user.avatarUrl;
    return entity;
  };
  const users = await queryWithPaging(client, query, (r) => {
    var _a;
    return (_a = r.organization) == null ? void 0 : _a.membersWithRole;
  }, mapper, {org});
  return {users};
}
async function getOrganizationTeams(client, org) {
  const query = `
    query teams($org: String!, $cursor: String) {
      organization(login: $org) {
        teams(first: 100, after: $cursor) {
          pageInfo { hasNextPage, endCursor }
          nodes {
            slug
            combinedSlug
            name
            description
            avatarUrl
            parentTeam { slug }
            members(first: 100, membership: IMMEDIATE) {
              pageInfo { hasNextPage }
              nodes { login }
            }
          }
        }
      }
    }`;
  const groupMemberUsers = new Map();
  const mapper = async (team) => {
    const entity = {
      apiVersion: "backstage.io/v1alpha1",
      kind: "Group",
      metadata: {
        name: team.slug,
        annotations: {
          "github.com/team-slug": team.combinedSlug
        }
      },
      spec: {
        type: "team",
        profile: {},
        children: []
      }
    };
    if (team.description) {
      entity.metadata.description = team.description;
    }
    if (team.name) {
      entity.spec.profile.displayName = team.name;
    }
    if (team.avatarUrl) {
      entity.spec.profile.picture = team.avatarUrl;
    }
    if (team.parentTeam) {
      entity.spec.parent = team.parentTeam.slug;
    }
    const memberNames = [];
    groupMemberUsers.set(team.slug, memberNames);
    if (!team.members.pageInfo.hasNextPage) {
      for (const user of team.members.nodes) {
        memberNames.push(user.login);
      }
    } else {
      const {members} = await getTeamMembers(client, org, team.slug);
      for (const userLogin of members) {
        memberNames.push(userLogin);
      }
    }
    return entity;
  };
  const groups = await queryWithPaging(client, query, (r) => {
    var _a;
    return (_a = r.organization) == null ? void 0 : _a.teams;
  }, mapper, {org});
  return {groups, groupMemberUsers};
}
async function getOrganizationRepositories(client, org) {
  const query = `
    query repositories($org: String!, $cursor: String) {
      repositoryOwner(login: $org) {
        login
        repositories(first: 100, after: $cursor) {
          nodes {
            name
            url
            isArchived
          }
          pageInfo {
            hasNextPage
            endCursor
          }
        }
      }
    }`;
  const repositories = await queryWithPaging(client, query, (r) => {
    var _a;
    return (_a = r.repositoryOwner) == null ? void 0 : _a.repositories;
  }, (x) => x, {org});
  return {repositories};
}
async function getTeamMembers(client, org, teamSlug) {
  const query = `
    query members($org: String!, $teamSlug: String!, $cursor: String) {
      organization(login: $org) {
        team(slug: $teamSlug) {
          members(first: 100, after: $cursor, membership: IMMEDIATE) {
            pageInfo { hasNextPage, endCursor }
            nodes { login }
          }
        }
      }
    }`;
  const members = await queryWithPaging(client, query, (r) => {
    var _a, _b;
    return (_b = (_a = r.organization) == null ? void 0 : _a.team) == null ? void 0 : _b.members;
  }, (user) => user.login, {org, teamSlug});
  return {members};
}
async function queryWithPaging(client, query, connection, mapper, variables) {
  const result = [];
  let cursor = void 0;
  for (let j = 0; j < 1e3; ++j) {
    const response = await client(query, {
      ...variables,
      cursor
    });
    const conn = connection(response);
    if (!conn) {
      throw new Error(`Found no match for ${JSON.stringify(variables)}`);
    }
    for (const node of conn.nodes) {
      result.push(await mapper(node));
    }
    if (!conn.pageInfo.hasNextPage) {
      break;
    } else {
      cursor = conn.pageInfo.endCursor;
    }
  }
  return result;
}

class GithubDiscoveryProcessor {
  static fromConfig(config, options) {
    const integrations = integration.ScmIntegrations.fromConfig(config);
    return new GithubDiscoveryProcessor({
      ...options,
      integrations
    });
  }
  constructor(options) {
    this.integrations = options.integrations;
    this.logger = options.logger;
  }
  async readLocation(location$1, _optional, emit) {
    var _a;
    if (location$1.type !== "github-discovery") {
      return false;
    }
    const gitHubConfig = (_a = this.integrations.github.byUrl(location$1.target)) == null ? void 0 : _a.config;
    if (!gitHubConfig) {
      throw new Error(`There is no GitHub integration that matches ${location$1.target}. Please add a configuration entry for it under integrations.github`);
    }
    const {headers} = await integration.GithubCredentialsProvider.create(gitHubConfig).getCredentials({url: location$1.target});
    const {org, repoSearchPath, catalogPath} = parseUrl$1(location$1.target);
    const client = graphql.graphql.defaults({
      baseUrl: gitHubConfig.apiBaseUrl,
      headers
    });
    const startTimestamp = Date.now();
    this.logger.info(`Reading GitHub repositories from ${location$1.target}`);
    const {repositories} = await getOrganizationRepositories(client, org);
    const matching = repositories.filter((r) => !r.isArchived && repoSearchPath.test(r.name));
    const duration = ((Date.now() - startTimestamp) / 1e3).toFixed(1);
    this.logger.debug(`Read ${repositories.length} GitHub repositories (${matching.length} matching the pattern) in ${duration} seconds`);
    for (const repository of matching) {
      emit(location({
        type: "url",
        target: `${repository.url}${catalogPath}`
      }, true));
    }
    return true;
  }
}
function parseUrl$1(urlString) {
  const url = new URL(urlString);
  const path = url.pathname.substr(1).split("/");
  if (path.length > 2 && path[0].length && path[1].length) {
    return {
      org: decodeURIComponent(path[0]),
      repoSearchPath: escapeRegExp$1(decodeURIComponent(path[1])),
      catalogPath: `/${decodeURIComponent(path.slice(2).join("/"))}`
    };
  }
  throw new Error(`Failed to parse ${urlString}`);
}
function escapeRegExp$1(str) {
  return new RegExp(`^${str.replace(/\*/g, ".*")}$`);
}

function buildOrgHierarchy(groups) {
  const groupsByName = new Map(groups.map((g) => [g.metadata.name, g]));
  for (const group of groups) {
    const selfName = group.metadata.name;
    const parentName = group.spec.parent;
    if (parentName) {
      const parent = groupsByName.get(parentName);
      if (parent && !parent.spec.children.includes(selfName)) {
        parent.spec.children.push(selfName);
      }
    }
  }
  for (const group of groups) {
    const selfName = group.metadata.name;
    for (const childName of group.spec.children) {
      const child = groupsByName.get(childName);
      if (child && !child.spec.parent) {
        child.spec.parent = selfName;
      }
    }
  }
}
function buildMemberOf(groups, users) {
  const groupsByName = new Map(groups.map((g) => [g.metadata.name, g]));
  users.forEach((user) => {
    const transitiveMemberOf = new Set();
    const todo = [
      ...user.spec.memberOf,
      ...groups.filter((g) => {
        var _a;
        return (_a = g.spec.members) == null ? void 0 : _a.includes(user.metadata.name);
      }).map((g) => g.metadata.name)
    ];
    for (; ; ) {
      const current = todo.pop();
      if (!current) {
        break;
      }
      if (!transitiveMemberOf.has(current)) {
        transitiveMemberOf.add(current);
        const group = groupsByName.get(current);
        if (group == null ? void 0 : group.spec.parent) {
          todo.push(group.spec.parent);
        }
      }
    }
    user.spec.memberOf = [...transitiveMemberOf];
  });
}

class GithubOrgReaderProcessor {
  static fromConfig(config, options) {
    const integrations = integration.ScmIntegrations.fromConfig(config);
    return new GithubOrgReaderProcessor({
      ...options,
      providers: readGithubConfig(config),
      integrations
    });
  }
  constructor(options) {
    this.providers = options.providers;
    this.integrations = options.integrations;
    this.logger = options.logger;
  }
  async readLocation(location, _optional, emit) {
    if (location.type !== "github-org") {
      return false;
    }
    const client = await this.createClient(location.target);
    const {org} = parseUrl$2(location.target);
    const startTimestamp = Date.now();
    this.logger.info("Reading GitHub users and groups");
    const {users} = await getOrganizationUsers(client, org);
    const {groups, groupMemberUsers} = await getOrganizationTeams(client, org);
    const duration = ((Date.now() - startTimestamp) / 1e3).toFixed(1);
    this.logger.debug(`Read ${users.length} GitHub users and ${groups.length} GitHub groups in ${duration} seconds`);
    const usersByName = new Map(users.map((u) => [u.metadata.name, u]));
    for (const [groupName, userNames] of groupMemberUsers.entries()) {
      for (const userName of userNames) {
        const user = usersByName.get(userName);
        if (user && !user.spec.memberOf.includes(groupName)) {
          user.spec.memberOf.push(groupName);
        }
      }
    }
    buildOrgHierarchy(groups);
    for (const group of groups) {
      emit(entity(location, group));
    }
    for (const user of users) {
      emit(entity(location, user));
    }
    return true;
  }
  async createClient(orgUrl) {
    let client = await this.createClientFromIntegrations(orgUrl);
    if (!client) {
      client = await this.createClientFromProvider(orgUrl);
    }
    if (!client) {
      throw new Error(`There is no GitHub Org provider that matches ${orgUrl}. Please add a configuration for an integration or add an entry for it under catalog.processors.githubOrg.providers.`);
    }
    return client;
  }
  async createClientFromProvider(orgUrl) {
    const provider = this.providers.find((p) => orgUrl.startsWith(`${p.target}/`));
    if (!provider) {
      return void 0;
    }
    this.logger.warn("GithubOrgReaderProcessor uses provider defined in catalog.processors.githubOrg.providers, migrate to integrations instead. See https://backstage.io/docs/integrations/github/locations");
    return !provider.token ? graphql.graphql : graphql.graphql.defaults({
      baseUrl: provider.apiBaseUrl,
      headers: {
        authorization: `token ${provider.token}`
      }
    });
  }
  async createClientFromIntegrations(orgUrl) {
    var _a;
    const gitHubConfig = (_a = this.integrations.github.byUrl(orgUrl)) == null ? void 0 : _a.config;
    if (!gitHubConfig) {
      return void 0;
    }
    const credentialsProvider = integration.GithubCredentialsProvider.create(gitHubConfig);
    const {headers} = await credentialsProvider.getCredentials({
      url: orgUrl
    });
    return graphql.graphql.defaults({
      baseUrl: gitHubConfig.apiBaseUrl,
      headers
    });
  }
}
function parseUrl$2(urlString) {
  const path = new URL(urlString).pathname.substr(1).split("/");
  if (path.length === 1 && path[0].length) {
    return {org: decodeURIComponent(path[0])};
  }
  throw new Error(`Expected a URL pointing to /<org>`);
}

function errorString(error) {
  return `${error.code} ${error.name}: ${error.message}`;
}

const DefaultLdapVendor = {
  dnAttributeName: "entryDN",
  uuidAttributeName: "entryUUID",
  decodeStringAttribute: (entry, name) => {
    return decode(entry, name, (value) => {
      return value.toString();
    });
  }
};
const ActiveDirectoryVendor = {
  dnAttributeName: "distinguishedName",
  uuidAttributeName: "objectGUID",
  decodeStringAttribute: (entry, name) => {
    const decoder = (value) => {
      if (name === ActiveDirectoryVendor.uuidAttributeName) {
        return formatGUID(value);
      }
      return value.toString();
    };
    return decode(entry, name, decoder);
  }
};
function decode(entry, attributeName, decoder) {
  const values = entry.raw[attributeName];
  if (Array.isArray(values)) {
    return values.map((v) => {
      return decoder(v);
    });
  } else if (values) {
    return [decoder(values)];
  }
  return [];
}
function formatGUID(objectGUID) {
  let data;
  if (typeof objectGUID === "string") {
    data = new Buffer(objectGUID, "binary");
  } else {
    data = objectGUID;
  }
  let template = "{3}{2}{1}{0}-{5}{4}-{7}{6}-{8}{9}-{10}{11}{12}{13}{14}{15}";
  for (let i = 0; i < data.length; i++) {
    let dataStr = data[i].toString(16);
    dataStr = data[i] >= 16 ? dataStr : `0${dataStr}`;
    template = template.replace(`{${i}}`, dataStr);
  }
  return template;
}

class LdapClient {
  constructor(client) {
    this.client = client;
  }
  static async create(logger, target, bind) {
    const client = ldap__default['default'].createClient({url: target});
    client.on("error", (err) => {
      logger.warn(`LDAP client threw an error, ${errorString(err)}`);
    });
    if (!bind) {
      return new LdapClient(client);
    }
    return new Promise((resolve, reject) => {
      const {dn, secret} = bind;
      client.bind(dn, secret, (err) => {
        if (err) {
          reject(`LDAP bind failed for ${dn}, ${errorString(err)}`);
        } else {
          resolve(new LdapClient(client));
        }
      });
    });
  }
  async search(dn, options) {
    try {
      return await new Promise((resolve, reject) => {
        const output = [];
        this.client.search(dn, options, (err, res) => {
          if (err) {
            reject(new Error(errorString(err)));
            return;
          }
          res.on("searchReference", () => {
            reject(new Error("Unable to handle referral"));
          });
          res.on("searchEntry", (entry) => {
            output.push(entry);
          });
          res.on("error", (e) => {
            reject(new Error(errorString(e)));
          });
          res.on("end", (r) => {
            if (!r) {
              reject(new Error("Null response"));
            } else if (r.status !== 0) {
              reject(new Error(`Got status ${r.status}: ${r.errorMessage}`));
            } else {
              resolve(output);
            }
          });
        });
      });
    } catch (e) {
      throw new Error(`LDAP search at DN "${dn}" failed, ${e.message}`);
    }
  }
  async getVendor() {
    if (this.vendor) {
      return this.vendor;
    }
    this.vendor = this.getRootDSE().then((root) => {
      var _a;
      if (root && ((_a = root.raw) == null ? void 0 : _a.forestFunctionality)) {
        return ActiveDirectoryVendor;
      }
      return DefaultLdapVendor;
    }).catch((err) => {
      this.vendor = void 0;
      throw err;
    });
    return this.vendor;
  }
  async getRootDSE() {
    const result = await this.search("", {
      scope: "base",
      filter: "(objectclass=*)"
    });
    if (result && result.length === 1) {
      return result[0];
    }
    return void 0;
  }
}

const defaultConfig = {
  users: {
    options: {
      scope: "one",
      attributes: ["*", "+"]
    },
    map: {
      rdn: "uid",
      name: "uid",
      displayName: "cn",
      email: "mail",
      memberOf: "memberOf"
    }
  },
  groups: {
    options: {
      scope: "one",
      attributes: ["*", "+"]
    },
    map: {
      rdn: "cn",
      name: "cn",
      description: "description",
      displayName: "cn",
      type: "groupType",
      memberOf: "memberOf",
      members: "member"
    }
  }
};
function readLdapConfig(config) {
  var _a;
  function readBindConfig(c) {
    if (!c) {
      return void 0;
    }
    return {
      dn: c.getString("dn"),
      secret: c.getString("secret")
    };
  }
  function readOptionsConfig(c) {
    if (!c) {
      return {};
    }
    const paged = readOptionsPagedConfig(c);
    return {
      scope: c.getOptionalString("scope"),
      filter: formatFilter(c.getOptionalString("filter")),
      attributes: c.getOptionalStringArray("attributes"),
      ...paged !== void 0 ? {paged} : void 0
    };
  }
  function readOptionsPagedConfig(c) {
    const pagedConfig = c.getOptional("paged");
    if (pagedConfig === void 0) {
      return void 0;
    }
    if (pagedConfig === true || pagedConfig === false) {
      return pagedConfig;
    }
    const pageSize = c.getOptionalNumber("paged.pageSize");
    const pagePause = c.getOptionalBoolean("paged.pagePause");
    return {
      ...pageSize !== void 0 ? {pageSize} : void 0,
      ...pagePause !== void 0 ? {pagePause} : void 0
    };
  }
  function readSetConfig(c) {
    if (!c) {
      return void 0;
    }
    return Object.fromEntries(c.keys().map((path) => [path, c.get(path)]));
  }
  function readUserMapConfig(c) {
    if (!c) {
      return {};
    }
    return {
      rdn: c.getOptionalString("rdn"),
      name: c.getOptionalString("name"),
      description: c.getOptionalString("description"),
      displayName: c.getOptionalString("displayName"),
      email: c.getOptionalString("email"),
      picture: c.getOptionalString("picture"),
      memberOf: c.getOptionalString("memberOf")
    };
  }
  function readGroupMapConfig(c) {
    if (!c) {
      return {};
    }
    return {
      rdn: c.getOptionalString("rdn"),
      name: c.getOptionalString("name"),
      description: c.getOptionalString("description"),
      type: c.getOptionalString("type"),
      displayName: c.getOptionalString("displayName"),
      email: c.getOptionalString("email"),
      picture: c.getOptionalString("picture"),
      memberOf: c.getOptionalString("memberOf"),
      members: c.getOptionalString("members")
    };
  }
  function readUserConfig(c) {
    return {
      dn: c.getString("dn"),
      options: readOptionsConfig(c.getOptionalConfig("options")),
      set: readSetConfig(c.getOptionalConfig("set")),
      map: readUserMapConfig(c.getOptionalConfig("map"))
    };
  }
  function readGroupConfig(c) {
    return {
      dn: c.getString("dn"),
      options: readOptionsConfig(c.getOptionalConfig("options")),
      set: readSetConfig(c.getOptionalConfig("set")),
      map: readGroupMapConfig(c.getOptionalConfig("map"))
    };
  }
  function formatFilter(filter) {
    var _a2;
    return (_a2 = filter == null ? void 0 : filter.replace(/\s*(\(|\))/g, "$1")) == null ? void 0 : _a2.trim();
  }
  const providerConfigs = (_a = config.getOptionalConfigArray("providers")) != null ? _a : [];
  return providerConfigs.map((c) => {
    const newConfig = {
      target: c.getString("target").replace(/\/+$/, ""),
      bind: readBindConfig(c.getOptionalConfig("bind")),
      users: readUserConfig(c.getConfig("users")),
      groups: readGroupConfig(c.getConfig("groups"))
    };
    const merged = mergeWith__default['default']({}, defaultConfig, newConfig, (_into, from) => {
      return Array.isArray(from) ? from : void 0;
    });
    return merged;
  });
}

const LDAP_RDN_ANNOTATION = "backstage.io/ldap-rdn";
const LDAP_DN_ANNOTATION = "backstage.io/ldap-dn";
const LDAP_UUID_ANNOTATION = "backstage.io/ldap-uuid";

async function readLdapUsers(client, config) {
  const {dn, options, set, map} = config;
  const vendor = await client.getVendor();
  const entries = await client.search(dn, options);
  const entities = [];
  const userMemberOf = new Map();
  for (const entry of entries) {
    const entity = {
      apiVersion: "backstage.io/v1alpha1",
      kind: "User",
      metadata: {
        name: "",
        annotations: {}
      },
      spec: {
        profile: {},
        memberOf: []
      }
    };
    if (set) {
      for (const [path, value] of Object.entries(set)) {
        lodashSet__default['default'](entity, path, value);
      }
    }
    mapStringAttr(entry, vendor, map.name, (v) => {
      entity.metadata.name = v;
    });
    mapStringAttr(entry, vendor, map.description, (v) => {
      entity.metadata.description = v;
    });
    mapStringAttr(entry, vendor, map.rdn, (v) => {
      entity.metadata.annotations[LDAP_RDN_ANNOTATION] = v;
    });
    mapStringAttr(entry, vendor, vendor.uuidAttributeName, (v) => {
      entity.metadata.annotations[LDAP_UUID_ANNOTATION] = v;
    });
    mapStringAttr(entry, vendor, vendor.dnAttributeName, (v) => {
      entity.metadata.annotations[LDAP_DN_ANNOTATION] = v;
    });
    mapStringAttr(entry, vendor, map.displayName, (v) => {
      entity.spec.profile.displayName = v;
    });
    mapStringAttr(entry, vendor, map.email, (v) => {
      entity.spec.profile.email = v;
    });
    mapStringAttr(entry, vendor, map.picture, (v) => {
      entity.spec.profile.picture = v;
    });
    mapReferencesAttr(entry, vendor, map.memberOf, (myDn, vs) => {
      ensureItems(userMemberOf, myDn, vs);
    });
    entities.push(entity);
  }
  return {users: entities, userMemberOf};
}
async function readLdapGroups(client, config) {
  const {dn, options, set, map} = config;
  const vendor = await client.getVendor();
  const entries = await client.search(dn, options);
  const groups = [];
  const groupMemberOf = new Map();
  const groupMember = new Map();
  for (const entry of entries) {
    const entity = {
      apiVersion: "backstage.io/v1alpha1",
      kind: "Group",
      metadata: {
        name: "",
        annotations: {}
      },
      spec: {
        type: "unknown",
        profile: {},
        children: []
      }
    };
    if (set) {
      for (const [path, value] of Object.entries(set)) {
        lodashSet__default['default'](entity, path, value);
      }
    }
    mapStringAttr(entry, vendor, map.name, (v) => {
      entity.metadata.name = v;
    });
    mapStringAttr(entry, vendor, map.description, (v) => {
      entity.metadata.description = v;
    });
    mapStringAttr(entry, vendor, map.rdn, (v) => {
      entity.metadata.annotations[LDAP_RDN_ANNOTATION] = v;
    });
    mapStringAttr(entry, vendor, vendor.uuidAttributeName, (v) => {
      entity.metadata.annotations[LDAP_UUID_ANNOTATION] = v;
    });
    mapStringAttr(entry, vendor, vendor.dnAttributeName, (v) => {
      entity.metadata.annotations[LDAP_DN_ANNOTATION] = v;
    });
    mapStringAttr(entry, vendor, map.type, (v) => {
      entity.spec.type = v;
    });
    mapStringAttr(entry, vendor, map.displayName, (v) => {
      entity.spec.profile.displayName = v;
    });
    mapStringAttr(entry, vendor, map.email, (v) => {
      entity.spec.profile.email = v;
    });
    mapStringAttr(entry, vendor, map.picture, (v) => {
      entity.spec.profile.picture = v;
    });
    mapReferencesAttr(entry, vendor, map.memberOf, (myDn, vs) => {
      ensureItems(groupMemberOf, myDn, vs);
    });
    mapReferencesAttr(entry, vendor, map.members, (myDn, vs) => {
      ensureItems(groupMember, myDn, vs);
    });
    groups.push(entity);
  }
  return {
    groups,
    groupMemberOf,
    groupMember
  };
}
async function readLdapOrg(client, userConfig, groupConfig) {
  const {users, userMemberOf} = await readLdapUsers(client, userConfig);
  const {groups, groupMemberOf, groupMember} = await readLdapGroups(client, groupConfig);
  resolveRelations(groups, users, userMemberOf, groupMemberOf, groupMember);
  users.sort((a, b) => a.metadata.name.localeCompare(b.metadata.name));
  groups.sort((a, b) => a.metadata.name.localeCompare(b.metadata.name));
  return {users, groups};
}
function mapStringAttr(entry, vendor, attributeName, setter) {
  if (attributeName) {
    const values = vendor.decodeStringAttribute(entry, attributeName);
    if (values && values.length === 1) {
      setter(values[0]);
    }
  }
}
function mapReferencesAttr(entry, vendor, attributeName, setter) {
  if (attributeName) {
    const values = vendor.decodeStringAttribute(entry, attributeName);
    const dn = vendor.decodeStringAttribute(entry, vendor.dnAttributeName);
    if (values && dn && dn.length === 1) {
      setter(dn[0], values);
    }
  }
}
function ensureItems(target, key, values) {
  if (key) {
    let set = target.get(key);
    if (!set) {
      set = new Set();
      target.set(key, set);
    }
    for (const value of values) {
      if (value) {
        set.add(value);
      }
    }
  }
}
function resolveRelations(groups, users, userMemberOf, groupMemberOf, groupMember) {
  const userMap = new Map();
  const groupMap = new Map();
  for (const user of users) {
    userMap.set(user.metadata.name, user);
    userMap.set(user.metadata.annotations[LDAP_DN_ANNOTATION], user);
    userMap.set(user.metadata.annotations[LDAP_UUID_ANNOTATION], user);
  }
  for (const group of groups) {
    groupMap.set(group.metadata.name, group);
    groupMap.set(group.metadata.annotations[LDAP_DN_ANNOTATION], group);
    groupMap.set(group.metadata.annotations[LDAP_UUID_ANNOTATION], group);
  }
  userMap.delete("");
  groupMap.delete("");
  userMap.delete(void 0);
  groupMap.delete(void 0);
  const newUserMemberOf = new Map();
  const newGroupParents = new Map();
  const newGroupChildren = new Map();
  for (const [userN, groupsN] of userMemberOf.entries()) {
    const user = userMap.get(userN);
    if (user) {
      for (const groupN of groupsN) {
        const group = groupMap.get(groupN);
        if (group) {
          ensureItems(newUserMemberOf, user.metadata.name, [
            group.metadata.name
          ]);
        }
      }
    }
  }
  for (const [groupN, parentsN] of groupMemberOf.entries()) {
    const group = groupMap.get(groupN);
    if (group) {
      for (const parentN of parentsN) {
        const parentGroup = groupMap.get(parentN);
        if (parentGroup) {
          ensureItems(newGroupParents, group.metadata.name, [
            parentGroup.metadata.name
          ]);
          ensureItems(newGroupChildren, parentGroup.metadata.name, [
            group.metadata.name
          ]);
        }
      }
    }
  }
  for (const [groupN, membersN] of groupMember.entries()) {
    const group = groupMap.get(groupN);
    if (group) {
      for (const memberN of membersN) {
        const memberUser = userMap.get(memberN);
        if (memberUser) {
          ensureItems(newUserMemberOf, memberUser.metadata.name, [
            group.metadata.name
          ]);
        } else {
          const memberGroup = groupMap.get(memberN);
          if (memberGroup) {
            ensureItems(newGroupChildren, group.metadata.name, [
              memberGroup.metadata.name
            ]);
            ensureItems(newGroupParents, memberGroup.metadata.name, [
              group.metadata.name
            ]);
          }
        }
      }
    }
  }
  for (const [userN, groupsN] of newUserMemberOf.entries()) {
    const user = userMap.get(userN);
    if (user) {
      user.spec.memberOf = Array.from(groupsN).sort();
    }
  }
  for (const [groupN, parentsN] of newGroupParents.entries()) {
    if (parentsN.size === 1) {
      const group = groupMap.get(groupN);
      if (group) {
        group.spec.parent = parentsN.values().next().value;
      }
    }
  }
  for (const [groupN, childrenN] of newGroupChildren.entries()) {
    const group = groupMap.get(groupN);
    if (group) {
      group.spec.children = Array.from(childrenN).sort();
    }
  }
  buildOrgHierarchy(groups);
}

class LdapOrgReaderProcessor {
  static fromConfig(config, options) {
    const c = config.getOptionalConfig("catalog.processors.ldapOrg");
    return new LdapOrgReaderProcessor({
      ...options,
      providers: c ? readLdapConfig(c) : []
    });
  }
  constructor(options) {
    this.providers = options.providers;
    this.logger = options.logger;
  }
  async readLocation(location, _optional, emit) {
    if (location.type !== "ldap-org") {
      return false;
    }
    const provider = this.providers.find((p) => location.target === p.target);
    if (!provider) {
      throw new Error(`There is no LDAP Org provider that matches ${location.target}. Please add a configuration entry for it under catalog.processors.ldapOrg.providers.`);
    }
    const startTimestamp = Date.now();
    this.logger.info("Reading LDAP users and groups");
    const client = await LdapClient.create(this.logger, provider.target, provider.bind);
    const {users, groups} = await readLdapOrg(client, provider.users, provider.groups);
    const duration = ((Date.now() - startTimestamp) / 1e3).toFixed(1);
    this.logger.debug(`Read ${users.length} LDAP users and ${groups.length} LDAP groups in ${duration} seconds`);
    for (const group of groups) {
      emit(entity(location, group));
    }
    for (const user of users) {
      emit(entity(location, user));
    }
    return true;
  }
}

function toAbsoluteUrl(integrations, base, target) {
  try {
    if (base.type === "file") {
      if (target.startsWith(".")) {
        return path__default['default'].join(path__default['default'].dirname(base.target), target);
      }
      return target;
    }
    return integrations.resolveUrl({url: target, base: base.target});
  } catch (e) {
    return target;
  }
}
class LocationEntityProcessor {
  constructor(options) {
    this.options = options;
  }
  async postProcessEntity(entity, location$1, emit) {
    if (entity.kind === "Location") {
      const locationEntity = entity;
      const type = locationEntity.spec.type || location$1.type;
      if (type === "file" && location$1.target.endsWith(path__default['default'].sep)) {
        emit(inputError(location$1, `LocationEntityProcessor cannot handle ${type} type location with target ${location$1.target} that ends with a path separator`));
      }
      const targets = new Array();
      if (locationEntity.spec.target) {
        targets.push(locationEntity.spec.target);
      }
      if (locationEntity.spec.targets) {
        targets.push(...locationEntity.spec.targets);
      }
      for (const maybeRelativeTarget of targets) {
        const target = toAbsoluteUrl(this.options.integrations, location$1, maybeRelativeTarget);
        emit(location({type, target}, false));
      }
    }
    return entity;
  }
}

class MicrosoftGraphClient {
  constructor(baseUrl, pca) {
    this.baseUrl = baseUrl;
    this.pca = pca;
  }
  static create(config) {
    const clientConfig = {
      auth: {
        clientId: config.clientId,
        clientSecret: config.clientSecret,
        authority: `${config.authority}/${config.tenantId}`
      }
    };
    const pca = new msal.ConfidentialClientApplication(clientConfig);
    return new MicrosoftGraphClient(config.target, pca);
  }
  async *requestCollection(path, query) {
    let response = await this.requestApi(path, query);
    for (; ; ) {
      if (response.status !== 200) {
        await this.handleError(path, response);
      }
      const result = await response.json();
      const elements = result.value;
      yield* elements;
      if (!result["@odata.nextLink"]) {
        return;
      }
      response = await this.requestRaw(result["@odata.nextLink"]);
    }
  }
  async requestApi(path, query) {
    var _a, _b;
    const queryString = qs__default['default'].stringify({
      $filter: query == null ? void 0 : query.filter,
      $select: (_a = query == null ? void 0 : query.select) == null ? void 0 : _a.join(","),
      $expand: (_b = query == null ? void 0 : query.expand) == null ? void 0 : _b.join(",")
    }, {
      addQueryPrefix: true,
      encode: false
    });
    return await this.requestRaw(`${this.baseUrl}/${path}${queryString}`);
  }
  async requestRaw(url) {
    const token = await this.pca.acquireTokenByClientCredential({
      scopes: ["https://graph.microsoft.com/.default"]
    });
    if (!token) {
      throw new Error("Error while requesting token for Microsoft Graph");
    }
    return await fetch__default['default'](url, {
      headers: {
        Authorization: `Bearer ${token.accessToken}`
      }
    });
  }
  async getUserProfile(userId) {
    const response = await this.requestApi(`users/${userId}`);
    if (response.status !== 200) {
      await this.handleError("user profile", response);
    }
    return await response.json();
  }
  async getUserPhotoWithSizeLimit(userId, maxSize) {
    return await this.getPhotoWithSizeLimit("users", userId, maxSize);
  }
  async getUserPhoto(userId, sizeId) {
    return await this.getPhoto("users", userId, sizeId);
  }
  async *getUsers(query) {
    yield* this.requestCollection(`users`, query);
  }
  async getGroupPhotoWithSizeLimit(groupId, maxSize) {
    return await this.getPhotoWithSizeLimit("groups", groupId, maxSize);
  }
  async getGroupPhoto(groupId, sizeId) {
    return await this.getPhoto("groups", groupId, sizeId);
  }
  async *getGroups(query) {
    yield* this.requestCollection(`groups`, query);
  }
  async *getGroupMembers(groupId) {
    yield* this.requestCollection(`groups/${groupId}/members`);
  }
  async getOrganization(tenantId) {
    const response = await this.requestApi(`organization/${tenantId}`);
    if (response.status !== 200) {
      await this.handleError(`organization/${tenantId}`, response);
    }
    return await response.json();
  }
  async getPhotoWithSizeLimit(entityName, id, maxSize) {
    const response = await this.requestApi(`${entityName}/${id}/photos`);
    if (response.status === 404) {
      return void 0;
    } else if (response.status !== 200) {
      await this.handleError(`${entityName} photos`, response);
    }
    const result = await response.json();
    const photos = result.value;
    let selectedPhoto = void 0;
    for (const p of photos) {
      if (!selectedPhoto || p.height >= selectedPhoto.height && p.height <= maxSize) {
        selectedPhoto = p;
      }
    }
    if (!selectedPhoto) {
      return void 0;
    }
    return await this.getPhoto(entityName, id, selectedPhoto.id);
  }
  async getPhoto(entityName, id, sizeId) {
    const path = sizeId ? `${entityName}/${id}/photos/${sizeId}/$value` : `${entityName}/${id}/photo/$value`;
    const response = await this.requestApi(path);
    if (response.status === 404) {
      return void 0;
    } else if (response.status !== 200) {
      await this.handleError("photo", response);
    }
    return `data:image/jpeg;base64,${Buffer.from(await response.arrayBuffer()).toString("base64")}`;
  }
  async handleError(path, response) {
    const result = await response.json();
    const error = result.error;
    throw new Error(`Error while reading ${path} from Microsoft Graph: ${error.code} - ${error.message}`);
  }
}

function readMicrosoftGraphConfig(config) {
  var _a, _b;
  const providers = [];
  const providerConfigs = (_a = config.getOptionalConfigArray("providers")) != null ? _a : [];
  for (const providerConfig of providerConfigs) {
    const target = providerConfig.getString("target").replace(/\/+$/, "");
    const authority = ((_b = providerConfig.getOptionalString("authority")) == null ? void 0 : _b.replace(/\/+$/, "")) || "https://login.microsoftonline.com";
    const tenantId = providerConfig.getString("tenantId");
    const clientId = providerConfig.getString("clientId");
    const clientSecret = providerConfig.getString("clientSecret");
    const userFilter = providerConfig.getOptionalString("userFilter");
    const groupFilter = providerConfig.getOptionalString("groupFilter");
    providers.push({
      target,
      authority,
      tenantId,
      clientId,
      clientSecret,
      userFilter,
      groupFilter
    });
  }
  return providers;
}

const MICROSOFT_GRAPH_TENANT_ID_ANNOTATION = "graph.microsoft.com/tenant-id";
const MICROSOFT_GRAPH_GROUP_ID_ANNOTATION = "graph.microsoft.com/group-id";
const MICROSOFT_GRAPH_USER_ID_ANNOTATION = "graph.microsoft.com/user-id";

function normalizeEntityName(name) {
  return name.trim().toLocaleLowerCase().replace(/[^a-zA-Z0-9_\-\.]/g, "_");
}
async function readMicrosoftGraphUsers(client, options) {
  const entities = [];
  const promises = [];
  const limiter = limiterFactory__default['default'](10);
  for await (const user of client.getUsers({
    filter: options == null ? void 0 : options.userFilter,
    select: ["id", "displayName", "mail"]
  })) {
    if (!user.id || !user.displayName || !user.mail) {
      continue;
    }
    const name = normalizeEntityName(user.mail);
    const entity = {
      apiVersion: "backstage.io/v1alpha1",
      kind: "User",
      metadata: {
        name,
        annotations: {
          [MICROSOFT_GRAPH_USER_ID_ANNOTATION]: user.id
        }
      },
      spec: {
        profile: {
          displayName: user.displayName,
          email: user.mail
        },
        memberOf: []
      }
    };
    const loadPhoto = limiter(async () => {
      entity.spec.profile.picture = await client.getUserPhotoWithSizeLimit(user.id, 120);
    });
    promises.push(loadPhoto);
    entities.push(entity);
  }
  await Promise.all(promises);
  return {users: entities};
}
async function readMicrosoftGraphOrganization(client, tenantId) {
  const organization = await client.getOrganization(tenantId);
  const name = normalizeEntityName(organization.displayName);
  const rootGroup = {
    apiVersion: "backstage.io/v1alpha1",
    kind: "Group",
    metadata: {
      name,
      description: organization.displayName,
      annotations: {
        [MICROSOFT_GRAPH_TENANT_ID_ANNOTATION]: organization.id
      }
    },
    spec: {
      type: "root",
      profile: {
        displayName: organization.displayName
      },
      children: []
    }
  };
  return {rootGroup};
}
async function readMicrosoftGraphGroups(client, tenantId, options) {
  const groups = [];
  const groupMember = new Map();
  const groupMemberOf = new Map();
  const limiter = limiterFactory__default['default'](10);
  const {rootGroup} = await readMicrosoftGraphOrganization(client, tenantId);
  groupMember.set(rootGroup.metadata.name, new Set());
  groups.push(rootGroup);
  const promises = [];
  for await (const group of client.getGroups({
    filter: options == null ? void 0 : options.groupFilter,
    select: ["id", "displayName", "description", "mail", "mailNickname"]
  })) {
    if (!group.id || !group.displayName) {
      continue;
    }
    const name = normalizeEntityName(group.mailNickname || group.displayName);
    const entity = {
      apiVersion: "backstage.io/v1alpha1",
      kind: "Group",
      metadata: {
        name,
        annotations: {
          [MICROSOFT_GRAPH_GROUP_ID_ANNOTATION]: group.id
        }
      },
      spec: {
        type: "team",
        profile: {},
        children: []
      }
    };
    if (group.description) {
      entity.metadata.description = group.description;
    }
    if (group.displayName) {
      entity.spec.profile.displayName = group.displayName;
    }
    if (group.mail) {
      entity.spec.profile.email = group.mail;
    }
    const loadGroupMembers = limiter(async () => {
      for await (const member of client.getGroupMembers(group.id)) {
        if (!member.id) {
          continue;
        }
        if (member["@odata.type"] === "#microsoft.graph.user") {
          ensureItem(groupMemberOf, member.id, group.id);
        }
        if (member["@odata.type"] === "#microsoft.graph.group") {
          ensureItem(groupMember, group.id, member.id);
        }
      }
    });
    promises.push(loadGroupMembers);
    groups.push(entity);
  }
  await Promise.all(promises);
  return {
    groups,
    rootGroup,
    groupMember,
    groupMemberOf
  };
}
function resolveRelations$1(rootGroup, groups, users, groupMember, groupMemberOf) {
  const groupMap = new Map();
  for (const group of groups) {
    if (group.metadata.annotations[MICROSOFT_GRAPH_GROUP_ID_ANNOTATION]) {
      groupMap.set(group.metadata.annotations[MICROSOFT_GRAPH_GROUP_ID_ANNOTATION], group);
    }
    if (group.metadata.annotations[MICROSOFT_GRAPH_TENANT_ID_ANNOTATION]) {
      groupMap.set(group.metadata.annotations[MICROSOFT_GRAPH_TENANT_ID_ANNOTATION], group);
    }
  }
  const parentGroups = new Map();
  groupMember.forEach((members, groupId) => members.forEach((m) => ensureItem(parentGroups, m, groupId)));
  if (rootGroup) {
    const tenantId = rootGroup.metadata.annotations[MICROSOFT_GRAPH_TENANT_ID_ANNOTATION];
    groups.forEach((group) => {
      const groupId = group.metadata.annotations[MICROSOFT_GRAPH_GROUP_ID_ANNOTATION];
      if (!groupId) {
        return;
      }
      if (retrieveItems(parentGroups, groupId).size === 0) {
        ensureItem(parentGroups, groupId, tenantId);
        ensureItem(groupMember, tenantId, groupId);
      }
    });
  }
  groups.forEach((group) => {
    var _a;
    const id = (_a = group.metadata.annotations[MICROSOFT_GRAPH_GROUP_ID_ANNOTATION]) != null ? _a : group.metadata.annotations[MICROSOFT_GRAPH_TENANT_ID_ANNOTATION];
    retrieveItems(groupMember, id).forEach((m) => {
      const childGroup = groupMap.get(m);
      if (childGroup) {
        group.spec.children.push(childGroup.metadata.name);
      }
    });
    retrieveItems(parentGroups, id).forEach((p) => {
      const parentGroup = groupMap.get(p);
      if (parentGroup) {
        group.spec.parent = parentGroup.metadata.name;
      }
    });
  });
  buildOrgHierarchy(groups);
  users.forEach((user) => {
    const id = user.metadata.annotations[MICROSOFT_GRAPH_USER_ID_ANNOTATION];
    retrieveItems(groupMemberOf, id).forEach((p) => {
      const parentGroup = groupMap.get(p);
      if (parentGroup) {
        user.spec.memberOf.push(parentGroup.metadata.name);
      }
    });
  });
  buildMemberOf(groups, users);
}
async function readMicrosoftGraphOrg(client, tenantId, options) {
  const {users} = await readMicrosoftGraphUsers(client, {
    userFilter: options == null ? void 0 : options.userFilter
  });
  const {
    groups,
    rootGroup,
    groupMember,
    groupMemberOf
  } = await readMicrosoftGraphGroups(client, tenantId, {
    groupFilter: options == null ? void 0 : options.groupFilter
  });
  resolveRelations$1(rootGroup, groups, users, groupMember, groupMemberOf);
  users.sort((a, b) => a.metadata.name.localeCompare(b.metadata.name));
  groups.sort((a, b) => a.metadata.name.localeCompare(b.metadata.name));
  return {users, groups};
}
function ensureItem(target, key, value) {
  let set = target.get(key);
  if (!set) {
    set = new Set();
    target.set(key, set);
  }
  set.add(value);
}
function retrieveItems(target, key) {
  var _a;
  return (_a = target.get(key)) != null ? _a : new Set();
}

class MicrosoftGraphOrgReaderProcessor {
  static fromConfig(config, options) {
    const c = config.getOptionalConfig("catalog.processors.microsoftGraphOrg");
    return new MicrosoftGraphOrgReaderProcessor({
      ...options,
      providers: c ? readMicrosoftGraphConfig(c) : []
    });
  }
  constructor(options) {
    this.providers = options.providers;
    this.logger = options.logger;
  }
  async readLocation(location, _optional, emit) {
    if (location.type !== "microsoft-graph-org") {
      return false;
    }
    const provider = this.providers.find((p) => location.target.startsWith(p.target));
    if (!provider) {
      throw new Error(`There is no Microsoft Graph Org provider that matches ${location.target}. Please add a configuration entry for it under catalog.processors.microsoftGraphOrg.providers.`);
    }
    const startTimestamp = Date.now();
    this.logger.info("Reading Microsoft Graph users and groups");
    const client = MicrosoftGraphClient.create(provider);
    const {users, groups} = await readMicrosoftGraphOrg(client, provider.tenantId, {
      userFilter: provider.userFilter,
      groupFilter: provider.groupFilter
    });
    const duration = ((Date.now() - startTimestamp) / 1e3).toFixed(1);
    this.logger.debug(`Read ${users.length} users and ${groups.length} groups from Microsoft Graph in ${duration} seconds`);
    for (const group of groups) {
      emit(entity(location, group));
    }
    for (const user of users) {
      emit(entity(location, user));
    }
    return true;
  }
}

class PlaceholderProcessor {
  constructor(options) {
    this.options = options;
  }
  async preProcessEntity(entity, location) {
    const process = async (data) => {
      if (!data || !(data instanceof Object)) {
        return [data, false];
      }
      if (Array.isArray(data)) {
        const items = await Promise.all(data.map((item) => process(item)));
        return items.every(([, changed]) => !changed) ? [data, false] : [items.map(([item]) => item), true];
      }
      const keys = Object.keys(data);
      if (!keys.some((k) => k.startsWith("$"))) {
        const entries = await Promise.all(Object.entries(data).map(([k, v]) => process(v).then((vp) => [k, vp])));
        return entries.every(([, [, changed]]) => !changed) ? [data, false] : [Object.fromEntries(entries.map(([k, [v]]) => [k, v])), true];
      } else if (keys.length !== 1) {
        return [data, false];
      }
      const resolverKey = keys[0].substr(1);
      const resolverValue = data[keys[0]];
      const resolver = this.options.resolvers[resolverKey];
      if (!resolver || typeof resolverValue !== "string") {
        return [data, false];
      }
      return [
        await resolver({
          key: resolverKey,
          value: resolverValue,
          baseUrl: location.target,
          read: this.options.reader.read.bind(this.options.reader)
        }),
        true
      ];
    };
    const [result] = await process(entity);
    return result;
  }
}
async function yamlPlaceholderResolver(params) {
  var _a;
  const text = await readTextLocation(params);
  let documents;
  try {
    documents = yaml__default['default'].parseAllDocuments(text).filter((d) => d);
  } catch (e) {
    throw new Error(`Placeholder $${params.key} failed to parse YAML data at ${params.value}, ${e}`);
  }
  if (documents.length !== 1) {
    throw new Error(`Placeholder $${params.key} expected to find exactly one document of data at ${params.value}, found ${documents.length}`);
  }
  const document = documents[0];
  if ((_a = document.errors) == null ? void 0 : _a.length) {
    throw new Error(`Placeholder $${params.key} found an error in the data at ${params.value}, ${document.errors[0]}`);
  }
  return document.toJSON();
}
async function jsonPlaceholderResolver(params) {
  const text = await readTextLocation(params);
  try {
    return JSON.parse(text);
  } catch (e) {
    throw new Error(`Placeholder $${params.key} failed to parse JSON data at ${params.value}, ${e}`);
  }
}
async function textPlaceholderResolver(params) {
  return await readTextLocation(params);
}
async function readTextLocation(params) {
  const newUrl = relativeUrl(params);
  try {
    const data = await params.read(newUrl);
    return data.toString("utf-8");
  } catch (e) {
    throw new Error(`Placeholder $${params.key} could not read location ${params.value}, ${e}`);
  }
}
function relativeUrl({key, value, baseUrl}) {
  if (typeof value !== "string") {
    throw new Error(`Placeholder $${key} expected a string value parameter, in the form of an absolute URL or a relative path`);
  }
  let url;
  try {
    url = new URL(value, baseUrl);
  } catch {
    try {
      url = new URL(value);
    } catch {
      throw new Error(`Placeholder $${key} could not form a URL out of ${baseUrl} and ${value}`);
    }
  }
  return url.toString();
}

class StaticLocationProcessor {
  constructor(staticLocations) {
    this.staticLocations = staticLocations;
  }
  static fromConfig(config) {
    var _a;
    const locations = [];
    const lConfigs = (_a = config.getOptionalConfigArray("catalog.locations")) != null ? _a : [];
    for (const lConfig of lConfigs) {
      const type = lConfig.getString("type");
      const target = lConfig.getString("target");
      locations.push({type, target});
    }
    return new StaticLocationProcessor(locations);
  }
  async readLocation(location$1, _optional, emit) {
    if (location$1.type !== "bootstrap") {
      return false;
    }
    for (const staticLocation of this.staticLocations) {
      emit(location(staticLocation, false));
    }
    return true;
  }
}

const deprecatedTypes = [
  "github",
  "github/api",
  "bitbucket/api",
  "gitlab/api",
  "azure/api"
];
class UrlReaderProcessor {
  constructor(options) {
    this.options = options;
  }
  async readLocation(location, optional, emit, parser) {
    if (deprecatedTypes.includes(location.type)) {
      this.options.logger.warn(`Location '${location.target}' uses deprecated location type '${location.type}', use 'url' instead. Use "scripts/migrate-location-types.js" in the Backstage repo to migrate existing locations.`);
    } else if (location.type !== "url") {
      return false;
    }
    try {
      const output = await this.doRead(location.target);
      for (const item of output) {
        for await (const parseResult of parser({
          data: item.data,
          location: {type: location.type, target: item.url}
        })) {
          emit(parseResult);
        }
      }
    } catch (error) {
      const message = `Unable to read ${location.type}, ${error}`;
      if (error.name === "NotFoundError") {
        if (!optional) {
          emit(notFoundError(location, message));
        }
      } else {
        emit(generalError(location, message));
      }
    }
    return true;
  }
  async doRead(location) {
    const {filepath} = parseGitUrl__default['default'](location);
    if (filepath == null ? void 0 : filepath.match(/[*?]/)) {
      const limiter = limiterFactory__default['default'](5);
      const response = await this.options.reader.search(location);
      const output = response.files.map(async (file) => ({
        url: file.url,
        data: await limiter(file.content)
      }));
      return Promise.all(output);
    }
    const data = await this.options.reader.read(location);
    return [{url: location, data}];
  }
}

class DefaultCatalogCollator {
  constructor({
    discovery,
    locationTemplate
  }) {
    this.discovery = discovery;
    this.locationTemplate = locationTemplate || "/catalog/:namespace/:kind/:name";
  }
  applyArgsToFormat(format, args) {
    let formatted = format;
    for (const [key, value] of Object.entries(args)) {
      formatted = formatted.replace(`:${key}`, value);
    }
    return formatted.toLowerCase();
  }
  async execute() {
    const baseUrl = await this.discovery.getBaseUrl("catalog");
    const res = await fetch__default['default'](`${baseUrl}/entities`);
    const entities = await res.json();
    return entities.map((entity) => {
      var _a, _b, _c, _d;
      return {
        title: entity.metadata.name,
        location: this.applyArgsToFormat(this.locationTemplate, {
          namespace: entity.metadata.namespace || "default",
          kind: entity.kind,
          name: entity.metadata.name
        }),
        text: entity.metadata.description || "",
        componentType: ((_b = (_a = entity.spec) == null ? void 0 : _a.type) == null ? void 0 : _b.toString()) || "other",
        namespace: entity.metadata.namespace || "default",
        kind: entity.kind,
        lifecycle: ((_c = entity.spec) == null ? void 0 : _c.lifecycle) || "",
        owner: ((_d = entity.spec) == null ? void 0 : _d.owner) || ""
      };
    });
  }
}

const _CatalogRulesEnforcer = class {
  constructor(rules) {
    this.rules = rules;
  }
  static fromConfig(config) {
    const rules = new Array();
    if (config.has("catalog.rules")) {
      const globalRules = config.getConfigArray("catalog.rules").map((sub) => ({
        allow: sub.getStringArray("allow").map((kind) => ({kind}))
      }));
      rules.push(...globalRules);
    } else {
      rules.push(..._CatalogRulesEnforcer.defaultRules);
    }
    if (config.has("catalog.locations")) {
      const locationRules = config.getConfigArray("catalog.locations").flatMap((locConf) => {
        if (!locConf.has("rules")) {
          return [];
        }
        const type = locConf.getString("type");
        const target = locConf.getString("target");
        return locConf.getConfigArray("rules").map((ruleConf) => ({
          allow: ruleConf.getStringArray("allow").map((kind) => ({kind})),
          locations: [{type, target}]
        }));
      });
      rules.push(...locationRules);
    }
    return new _CatalogRulesEnforcer(rules);
  }
  isAllowed(entity, location) {
    for (const rule of this.rules) {
      if (!this.matchLocation(location, rule.locations)) {
        continue;
      }
      if (this.matchEntity(entity, rule.allow)) {
        return true;
      }
    }
    return false;
  }
  matchLocation(location, matchers) {
    if (!matchers) {
      return true;
    }
    for (const matcher of matchers) {
      if (matcher.type !== (location == null ? void 0 : location.type)) {
        continue;
      }
      if (matcher.target && matcher.target !== (location == null ? void 0 : location.target)) {
        continue;
      }
      return true;
    }
    return false;
  }
  matchEntity(entity, matchers) {
    var _a;
    if (!matchers) {
      return true;
    }
    for (const matcher of matchers) {
      if (((_a = entity == null ? void 0 : entity.kind) == null ? void 0 : _a.toLowerCase()) !== matcher.kind.toLowerCase()) {
        continue;
      }
      return true;
    }
    return false;
  }
};
let CatalogRulesEnforcer = _CatalogRulesEnforcer;
CatalogRulesEnforcer.defaultRules = [
  {
    allow: ["Component", "API", "Location"].map((kind) => ({kind}))
  }
];

class RepoLocationAnalyzer {
  constructor(logger, scmIntegrations) {
    this.logger = logger;
    this.scmIntegrations = scmIntegrations;
  }
  async analyzeLocation(request) {
    const {owner, name} = parseGitUrl__default['default'](request.location.target);
    const entity = {
      apiVersion: "backstage.io/v1alpha1",
      kind: "Component",
      metadata: {
        name
      },
      spec: {type: "other", lifecycle: "unknown"}
    };
    const integration = this.scmIntegrations.byUrl(request.location.target);
    let annotationPrefix;
    switch (integration == null ? void 0 : integration.type) {
      case "azure":
        annotationPrefix = "dev.azure.com";
        break;
      case "bitbucket":
        annotationPrefix = "bitbucket.org";
        break;
      case "github":
        annotationPrefix = "github.com";
        break;
      case "gitlab":
        annotationPrefix = "gitlab.com";
        break;
    }
    if (annotationPrefix) {
      entity.metadata.annotations = {
        [`${annotationPrefix}/project-slug`]: `${owner}/${name}`
      };
    }
    this.logger.debug(`entity created for ${request.location.target}`);
    return {
      existingEntityFiles: [],
      generateEntities: [{entity, fields: []}]
    };
  }
}

class CatalogBuilder {
  constructor(env) {
    this.env = env;
    this.entityPolicies = [];
    this.entityPoliciesReplace = false;
    this.placeholderResolvers = {};
    this.fieldFormatValidators = {};
    this.processors = [];
    this.processorsReplace = false;
    this.parser = void 0;
  }
  addEntityPolicy(...policies) {
    this.entityPolicies.push(...policies);
    return this;
  }
  replaceEntityPolicies(policies) {
    this.entityPolicies = [...policies];
    this.entityPoliciesReplace = true;
    return this;
  }
  setPlaceholderResolver(key, resolver) {
    this.placeholderResolvers[key] = resolver;
    return this;
  }
  setFieldFormatValidators(validators) {
    lodash__default['default'].merge(this.fieldFormatValidators, validators);
    return this;
  }
  addProcessor(...processors) {
    this.processors.push(...processors);
    return this;
  }
  replaceProcessors(processors) {
    this.processors = [...processors];
    this.processorsReplace = true;
    return this;
  }
  setEntityDataParser(parser) {
    this.parser = parser;
    return this;
  }
  async build() {
    const {config, database, logger} = this.env;
    const integrations = integration.ScmIntegrations.fromConfig(config);
    const policy = this.buildEntityPolicy();
    const processors = this.buildProcessors();
    const rulesEnforcer = CatalogRulesEnforcer.fromConfig(config);
    const parser = this.parser || defaultEntityDataParser;
    const locationReader = new LocationReaders({
      ...this.env,
      parser,
      processors,
      rulesEnforcer,
      policy
    });
    const db = await DatabaseManager.createDatabase(await database.getClient(), {logger});
    const entitiesCatalog = new DatabaseEntitiesCatalog(db, this.env.logger);
    const locationsCatalog = new DatabaseLocationsCatalog(db);
    const higherOrderOperation = new HigherOrderOperations(entitiesCatalog, locationsCatalog, locationReader, logger);
    const locationAnalyzer = new RepoLocationAnalyzer(logger, integrations);
    return {
      entitiesCatalog,
      locationsCatalog,
      higherOrderOperation,
      locationAnalyzer
    };
  }
  buildEntityPolicy() {
    const entityPolicies = this.entityPoliciesReplace ? [new catalogModel.SchemaValidEntityPolicy(), ...this.entityPolicies] : [
      new catalogModel.SchemaValidEntityPolicy(),
      new catalogModel.DefaultNamespaceEntityPolicy(),
      new catalogModel.NoForeignRootFieldsEntityPolicy(),
      new catalogModel.FieldFormatEntityPolicy(catalogModel.makeValidator(this.fieldFormatValidators)),
      ...this.entityPolicies
    ];
    return catalogModel.EntityPolicies.allOf(entityPolicies);
  }
  buildProcessors() {
    const {config, logger, reader} = this.env;
    const integrations = integration.ScmIntegrations.fromConfig(config);
    this.checkDeprecatedReaderProcessors();
    const placeholderResolvers = {
      json: jsonPlaceholderResolver,
      yaml: yamlPlaceholderResolver,
      text: textPlaceholderResolver,
      ...this.placeholderResolvers
    };
    const processors = [
      StaticLocationProcessor.fromConfig(config),
      new PlaceholderProcessor({resolvers: placeholderResolvers, reader}),
      new BuiltinKindsEntityProcessor()
    ];
    if (!this.processorsReplace) {
      processors.push(new FileReaderProcessor(), BitbucketDiscoveryProcessor.fromConfig(config, {logger}), GithubDiscoveryProcessor.fromConfig(config, {logger}), GithubOrgReaderProcessor.fromConfig(config, {logger}), LdapOrgReaderProcessor.fromConfig(config, {logger}), MicrosoftGraphOrgReaderProcessor.fromConfig(config, {logger}), new UrlReaderProcessor({reader, logger}), CodeOwnersProcessor.fromConfig(config, {logger, reader}), new LocationEntityProcessor({integrations}), new AnnotateLocationEntityProcessor({integrations}));
    }
    processors.push(...this.processors);
    return processors;
  }
  checkDeprecatedReaderProcessors() {
    const pc = this.env.config.getOptionalConfig("catalog.processors");
    if (pc == null ? void 0 : pc.has("github")) {
      throw new Error(`Using deprecated configuration for catalog.processors.github, move to using integrations.github instead`);
    }
    if (pc == null ? void 0 : pc.has("gitlabApi")) {
      throw new Error(`Using deprecated configuration for catalog.processors.gitlabApi, move to using integrations.gitlab instead`);
    }
    if (pc == null ? void 0 : pc.has("bitbucketApi")) {
      throw new Error(`Using deprecated configuration for catalog.processors.bitbucketApi, move to using integrations.bitbucket instead`);
    }
    if (pc == null ? void 0 : pc.has("azureApi")) {
      throw new Error(`Using deprecated configuration for catalog.processors.azureApi, move to using integrations.azure instead`);
    }
  }
}

async function requireRequestBody(req) {
  const contentType = req.header("content-type");
  if (!contentType) {
    throw new errors.InputError("Content-Type missing");
  } else if (!contentType.match(/^application\/json($|;)/)) {
    throw new errors.InputError("Illegal Content-Type");
  }
  const body = req.body;
  if (!body) {
    throw new errors.InputError("Missing request body");
  } else if (!lodash__default['default'].isPlainObject(body)) {
    throw new errors.InputError("Expected body to be a JSON object");
  } else if (Object.keys(body).length === 0) {
    throw new errors.InputError("Empty request body");
  }
  return body;
}
async function validateRequestBody(req, schema) {
  const body = await requireRequestBody(req);
  try {
    await schema.validate(body, {strict: true});
  } catch (e) {
    throw new errors.InputError(`Malformed request: ${e}`);
  }
  return body;
}
function disallowReadonlyMode(readonly) {
  if (readonly) {
    throw new errors.NotAllowedError("This operation not allowed in readonly mode");
  }
}

async function createRouter(options) {
  const {
    entitiesCatalog,
    locationsCatalog,
    higherOrderOperation,
    locationAnalyzer,
    config,
    logger
  } = options;
  const router = Router__default['default']();
  router.use(express__default['default'].json());
  const readonlyEnabled = config.getOptionalBoolean("catalog.readonly") || false;
  if (readonlyEnabled) {
    logger.info("Catalog is running in readonly mode");
  }
  if (entitiesCatalog) {
    router.get("/entities", async (req, res) => {
      const {entities, pageInfo} = await entitiesCatalog.entities({
        filter: parseEntityFilterParams(req.query),
        fields: parseEntityTransformParams(req.query),
        pagination: parseEntityPaginationParams(req.query)
      });
      if (pageInfo.hasNextPage) {
        const url = new URL(`http://ignored${req.url}`);
        url.searchParams.delete("offset");
        url.searchParams.set("after", pageInfo.endCursor);
        res.setHeader("link", `<${url.pathname}${url.search}>; rel="next"`);
      }
      res.json(entities);
    }).post("/entities", async (req, res) => {
      disallowReadonlyMode(readonlyEnabled);
      const body = await requireRequestBody(req);
      const [result] = await entitiesCatalog.batchAddOrUpdateEntities([
        {entity: body, relations: []}
      ]);
      const response = await entitiesCatalog.entities({
        filter: basicEntityFilter({"metadata.uid": result.entityId})
      });
      res.status(200).json(response.entities[0]);
    }).get("/entities/by-uid/:uid", async (req, res) => {
      const {uid} = req.params;
      const {entities} = await entitiesCatalog.entities({
        filter: basicEntityFilter({"metadata.uid": uid})
      });
      if (!entities.length) {
        throw new errors.NotFoundError(`No entity with uid ${uid}`);
      }
      res.status(200).json(entities[0]);
    }).delete("/entities/by-uid/:uid", async (req, res) => {
      const {uid} = req.params;
      await entitiesCatalog.removeEntityByUid(uid);
      res.status(204).end();
    }).get("/entities/by-name/:kind/:namespace/:name", async (req, res) => {
      const {kind, namespace, name} = req.params;
      const {entities} = await entitiesCatalog.entities({
        filter: basicEntityFilter({
          kind,
          "metadata.namespace": namespace,
          "metadata.name": name
        })
      });
      if (!entities.length) {
        throw new errors.NotFoundError(`No entity named '${name}' found, with kind '${kind}' in namespace '${namespace}'`);
      }
      res.status(200).json(entities[0]);
    });
  }
  if (higherOrderOperation) {
    router.post("/locations", async (req, res) => {
      const input = await validateRequestBody(req, catalogModel.locationSpecSchema);
      const dryRun = yn__default['default'](req.query.dryRun, {default: false});
      if (!dryRun) {
        disallowReadonlyMode(readonlyEnabled);
      }
      const output = await higherOrderOperation.addLocation(input, {dryRun});
      res.status(201).json(output);
    });
  }
  if (locationsCatalog) {
    router.get("/locations", async (_req, res) => {
      const output = await locationsCatalog.locations();
      res.status(200).json(output);
    }).get("/locations/:id/history", async (req, res) => {
      const {id} = req.params;
      const output = await locationsCatalog.locationHistory(id);
      res.status(200).json(output);
    }).get("/locations/:id", async (req, res) => {
      const {id} = req.params;
      const output = await locationsCatalog.location(id);
      res.status(200).json(output);
    }).delete("/locations/:id", async (req, res) => {
      disallowReadonlyMode(readonlyEnabled);
      const {id} = req.params;
      await locationsCatalog.removeLocation(id);
      res.status(204).end();
    });
  }
  if (locationAnalyzer) {
    router.post("/analyze-location", async (req, res) => {
      const input = await validateRequestBody(req, catalogModel.analyzeLocationSchema);
      const output = await locationAnalyzer.analyzeLocation(input);
      res.status(200).json(output);
    });
  }
  router.use(backendCommon.errorHandler());
  return router;
}

function locationSpecToMetadataName(location) {
  const hash = crypto.createHash("sha1").update(`${location.type}:${location.target}`).digest("hex");
  return `generated-${hash}`;
}
function locationSpecToLocationEntity(location, parentEntity) {
  var _a, _b;
  let ownLocation;
  let originLocation;
  if (parentEntity) {
    const maybeOwnLocation = (_a = parentEntity.metadata.annotations) == null ? void 0 : _a[catalogModel.LOCATION_ANNOTATION];
    if (!maybeOwnLocation) {
      throw new Error(`Parent entity '${catalogModel.stringifyEntityRef(parentEntity)}' of location '${catalogModel.stringifyLocationReference(location)}' does not have a location annotation`);
    }
    ownLocation = maybeOwnLocation;
    const maybeOriginLocation = (_b = parentEntity.metadata.annotations) == null ? void 0 : _b[catalogModel.ORIGIN_LOCATION_ANNOTATION];
    if (!maybeOriginLocation) {
      throw new Error(`Parent entity '${catalogModel.stringifyEntityRef(parentEntity)}' of location '${catalogModel.stringifyLocationReference(location)}' does not have an origin location annotation`);
    }
    originLocation = maybeOriginLocation;
  } else {
    ownLocation = catalogModel.stringifyLocationReference(location);
    originLocation = ownLocation;
  }
  const result = {
    apiVersion: "backstage.io/v1alpha1",
    kind: "Location",
    metadata: {
      name: locationSpecToMetadataName(location),
      annotations: {
        [catalogModel.LOCATION_ANNOTATION]: ownLocation,
        [catalogModel.ORIGIN_LOCATION_ANNOTATION]: originLocation
      }
    },
    spec: {
      type: location.type,
      target: location.target
    }
  };
  return result;
}

class ConfigLocationEntityProvider {
  constructor(config) {
    this.config = config;
  }
  getProviderName() {
    return "ConfigLocationProvider";
  }
  async connect(connection) {
    var _a;
    this.connection = connection;
    const locationConfigs = (_a = this.config.getOptionalConfigArray("catalog.locations")) != null ? _a : [];
    const entities = locationConfigs.map((location) => {
      const type = location.getString("type");
      const target = location.getString("target");
      return locationSpecToLocationEntity({
        type,
        target: type === "file" ? path__default['default'].resolve(target) : target
      });
    });
    await this.connection.applyMutation({
      type: "full",
      entities
    });
  }
}

const BATCH_SIZE$2 = 50;
class DefaultProcessingDatabase {
  constructor(database, logger) {
    this.database = database;
    this.logger = logger;
  }
  async updateProcessedEntity(txOpaque, options) {
    const tx = txOpaque;
    const {
      id,
      processedEntity,
      state,
      errors: errors$1,
      relations,
      deferredEntities
    } = options;
    const refreshResult = await tx("refresh_state").update({
      processed_entity: JSON.stringify(processedEntity),
      cache: JSON.stringify(state),
      errors: errors$1
    }).where("entity_id", id);
    if (refreshResult === 0) {
      throw new errors.NotFoundError(`Processing state not found for ${id}`);
    }
    await this.addUnprocessedEntities(tx, {
      entities: deferredEntities,
      entityRef: catalogModel.stringifyEntityRef(processedEntity)
    });
    await tx("relations").where({originating_entity_id: id}).delete();
    const relationRows = relations.map(({source, target, type}) => ({
      originating_entity_id: id,
      source_entity_ref: catalogModel.stringifyEntityRef(source),
      target_entity_ref: catalogModel.stringifyEntityRef(target),
      type
    }));
    await tx.batchInsert("relations", this.deduplicateRelations(relationRows), BATCH_SIZE$2);
  }
  deduplicateRelations(rows) {
    return lodash__default['default'].uniqBy(rows, (r) => `${r.source_entity_ref}:${r.target_entity_ref}:${r.type}`);
  }
  async createDelta(tx, options) {
    if (options.type === "delta") {
      return {
        toAdd: options.added,
        toRemove: options.removed.map((e) => catalogModel.stringifyEntityRef(e))
      };
    }
    const oldRefs = await tx("refresh_state_references").where({source_key: options.sourceKey}).select("target_entity_ref").then((rows) => rows.map((r) => r.target_entity_ref));
    const items = options.items.map((entity) => ({
      entity,
      ref: catalogModel.stringifyEntityRef(entity)
    }));
    const oldRefsSet = new Set(oldRefs);
    const newRefsSet = new Set(items.map((item) => item.ref));
    const toAdd = items.filter((item) => !oldRefsSet.has(item.ref));
    const toRemove = oldRefs.filter((ref) => !newRefsSet.has(ref));
    return {toAdd: toAdd.map(({entity}) => entity), toRemove};
  }
  async replaceUnprocessedEntities(txOpaque, options) {
    const tx = txOpaque;
    const {toAdd, toRemove} = await this.createDelta(tx, options);
    if (toRemove.length) {
      const removedCount = await tx("refresh_state").whereIn("entity_ref", function orphanedEntityRefs(orphans) {
        return orphans.withRecursive("descendants", function descendants(outer) {
          return outer.select({root_id: "id", entity_ref: "target_entity_ref"}).from("refresh_state_references").where("source_key", options.sourceKey).whereIn("target_entity_ref", toRemove).union(function recursive(inner) {
            return inner.select({
              root_id: "descendants.root_id",
              entity_ref: "refresh_state_references.target_entity_ref"
            }).from("descendants").join("refresh_state_references", {
              "descendants.entity_ref": "refresh_state_references.source_entity_ref"
            });
          });
        }).withRecursive("ancestors", function ancestors(outer) {
          return outer.select({
            root_id: tx.raw("CAST(NULL as INT)", []),
            via_entity_ref: "entity_ref",
            to_entity_ref: "entity_ref"
          }).from("descendants").union(function recursive(inner) {
            return inner.select({
              root_id: tx.raw("CASE WHEN source_key IS NOT NULL THEN id ELSE NULL END", []),
              via_entity_ref: "source_entity_ref",
              to_entity_ref: "ancestors.to_entity_ref"
            }).from("ancestors").join("refresh_state_references", {
              target_entity_ref: "ancestors.via_entity_ref"
            });
          });
        }).select("descendants.entity_ref").from("descendants").leftOuterJoin("ancestors", function keepaliveRoots() {
          this.on("ancestors.to_entity_ref", "=", "descendants.entity_ref");
          this.andOnNotNull("ancestors.root_id");
          this.andOn("ancestors.root_id", "!=", "descendants.root_id");
        }).whereNull("ancestors.root_id");
      }).delete();
      await tx("refresh_state_references").where("source_key", "=", options.sourceKey).whereIn("target_entity_ref", toRemove).delete();
      this.logger.debug(`removed, ${removedCount} entities: ${JSON.stringify(toRemove)}`);
    }
    if (toAdd.length) {
      const state = toAdd.map((entity) => ({
        entity_id: uuid.v4(),
        entity_ref: catalogModel.stringifyEntityRef(entity),
        unprocessed_entity: JSON.stringify(entity),
        errors: "",
        next_update_at: tx.fn.now(),
        last_discovery_at: tx.fn.now()
      }));
      const stateReferences = toAdd.map((entity) => ({
        source_key: options.sourceKey,
        target_entity_ref: catalogModel.stringifyEntityRef(entity)
      }));
      await tx.batchInsert("refresh_state", state, BATCH_SIZE$2);
      await tx.batchInsert("refresh_state_references", stateReferences, BATCH_SIZE$2);
    }
  }
  async addUnprocessedEntities(txOpaque, options) {
    const tx = txOpaque;
    const stateRows = options.entities.map((entity) => ({
      entity_id: uuid.v4(),
      entity_ref: catalogModel.stringifyEntityRef(entity),
      unprocessed_entity: JSON.stringify(entity),
      errors: "",
      next_update_at: tx.fn.now(),
      last_discovery_at: tx.fn.now()
    }));
    const stateReferenceRows = stateRows.map((stateRow) => ({
      source_entity_ref: options.entityRef,
      target_entity_ref: stateRow.entity_ref
    }));
    for (const row of stateRows) {
      await tx("refresh_state").insert(row).onConflict("entity_ref").merge(["unprocessed_entity", "last_discovery_at"]);
    }
    await tx("refresh_state_references").where({source_entity_ref: options.entityRef}).delete();
    await tx.batchInsert("refresh_state_references", stateReferenceRows, BATCH_SIZE$2);
  }
  async getProcessableEntities(txOpaque, request) {
    const tx = txOpaque;
    const items = await tx("refresh_state").select().where("next_update_at", "<=", tx.fn.now()).limit(request.processBatchSize).orderBy("next_update_at", "asc");
    await tx("refresh_state").whereIn("entity_ref", items.map((i) => i.entity_ref)).update({
      next_update_at: tx.client.config.client === "sqlite3" ? tx.raw(`datetime('now', ?)`, [`100 seconds`]) : tx.raw(`now() + interval '100 seconds'`)
    });
    return {
      items: items.map((i) => ({
        id: i.entity_id,
        entityRef: i.entity_ref,
        unprocessedEntity: JSON.parse(i.unprocessed_entity),
        processedEntity: i.processed_entity ? JSON.parse(i.processed_entity) : void 0,
        nextUpdateAt: i.next_update_at,
        lastDiscoveryAt: i.last_discovery_at,
        state: i.cache ? JSON.parse(i.cache) : new Map(),
        errors: i.errors
      }))
    };
  }
  async transaction(fn) {
    try {
      let result = void 0;
      await this.database.transaction(async (tx) => {
        result = await fn(tx);
      }, {
        doNotRejectOnRollback: true
      });
      return result;
    } catch (e) {
      this.logger.debug(`Error during transaction, ${e}`);
      if (/SQLITE_CONSTRAINT: UNIQUE/.test(e.message) || /unique constraint/.test(e.message)) {
        throw new errors.ConflictError(`Rejected due to a conflicting entity`, e);
      }
      throw e;
    }
  }
}

class Connection {
  constructor(config) {
    this.config = config;
  }
  async applyMutation(mutation) {
    const db = this.config.processingDatabase;
    if (mutation.type === "full") {
      await db.transaction(async (tx) => {
        await db.replaceUnprocessedEntities(tx, {
          sourceKey: this.config.id,
          type: "full",
          items: mutation.entities
        });
      });
      return;
    }
    await db.transaction(async (tx) => {
      await db.replaceUnprocessedEntities(tx, {
        sourceKey: this.config.id,
        type: "delta",
        added: mutation.added,
        removed: mutation.removed
      });
    });
  }
}
class DefaultCatalogProcessingEngine {
  constructor(logger, entityProviders, processingDatabase, orchestrator, stitcher) {
    this.logger = logger;
    this.entityProviders = entityProviders;
    this.processingDatabase = processingDatabase;
    this.orchestrator = orchestrator;
    this.stitcher = stitcher;
    this.running = false;
  }
  async start() {
    for (const provider of this.entityProviders) {
      await provider.connect(new Connection({
        processingDatabase: this.processingDatabase,
        id: provider.getProviderName()
      }));
    }
    this.running = true;
    this.run();
  }
  async run() {
    while (this.running) {
      try {
        await this.process();
      } catch (e) {
        this.logger.warn("Processing failed with:", e);
        await this.wait();
      }
    }
  }
  async process() {
    const {items} = await this.processingDatabase.transaction(async (tx) => {
      return this.processingDatabase.getProcessableEntities(tx, {
        processBatchSize: 1
      });
    });
    if (!items.length) {
      await this.wait();
      return;
    }
    const {id, state, unprocessedEntity} = items[0];
    const result = await this.orchestrator.process({
      entity: unprocessedEntity,
      state
    });
    for (const error of result.errors) {
      this.logger.warn(error.message);
    }
    if (!result.ok) {
      return;
    }
    result.completedEntity.metadata.uid = id;
    await this.processingDatabase.transaction(async (tx) => {
      await this.processingDatabase.updateProcessedEntity(tx, {
        id,
        processedEntity: result.completedEntity,
        state: result.state,
        errors: JSON.stringify(result.errors),
        relations: result.relations,
        deferredEntities: result.deferredEntities
      });
    });
    const setOfThingsToStitch = new Set([
      catalogModel.stringifyEntityRef(result.completedEntity),
      ...result.relations.map((relation) => catalogModel.stringifyEntityRef(relation.source))
    ]);
    await this.stitcher.stitch(setOfThingsToStitch);
  }
  async wait() {
    await new Promise((resolve) => setTimeout(resolve, 1e3));
  }
  async stop() {
    this.running = false;
  }
}

function isLocationEntity(entity) {
  return entity.kind === "Location";
}
function getEntityOriginLocationRef(entity) {
  var _a;
  const ref = (_a = entity.metadata.annotations) == null ? void 0 : _a[catalogModel.ORIGIN_LOCATION_ANNOTATION];
  if (!ref) {
    const entityRef = catalogModel.stringifyEntityRef(entity);
    throw new errors.InputError(`Entity '${entityRef}' does not have an origin location`);
  }
  return ref;
}
function toAbsoluteUrl$1(integrations, base, type, target) {
  if (base.type !== type) {
    return target;
  }
  try {
    if (type === "file") {
      if (target.startsWith(".")) {
        return path__default['default'].join(path__default['default'].dirname(base.target), target);
      }
      return target;
    } else if (type === "url") {
      return integrations.resolveUrl({url: target, base: base.target});
    }
    return target;
  } catch (e) {
    return target;
  }
}
class DefaultCatalogProcessingOrchestrator {
  constructor(options) {
    this.options = options;
  }
  async process(request) {
    return this.processSingleEntity(request.entity);
  }
  async processSingleEntity(unprocessedEntity) {
    var _a, _b;
    const entityRef = catalogModel.stringifyEntityRef(unprocessedEntity);
    const locationRef = (_b = (_a = unprocessedEntity.metadata) == null ? void 0 : _a.annotations) == null ? void 0 : _b[catalogModel.LOCATION_ANNOTATION];
    if (!locationRef) {
      throw new errors.InputError(`Entity '${entityRef}' does not have a location`);
    }
    const location = catalogModel.parseLocationReference(locationRef);
    const originLocation = catalogModel.parseLocationReference(getEntityOriginLocationRef(unprocessedEntity));
    const emitter = createEmitter(this.options.logger, unprocessedEntity);
    try {
      let entity = unprocessedEntity;
      for (const processor of this.options.processors) {
        if (processor.preProcessEntity) {
          try {
            entity = await processor.preProcessEntity(entity, location, emitter.emit, originLocation);
          } catch (e) {
            throw new Error(`Processor ${processor.constructor.name} threw an error while preprocessing entity ${entityRef} at ${locationRef}, ${e}`);
          }
        }
      }
      let policyEnforcedEntity;
      try {
        policyEnforcedEntity = await this.options.policy.enforce(entity);
      } catch (e) {
        throw new errors.InputError(`Policy check failed while analyzing entity ${entityRef} at ${locationRef}, ${e}`);
      }
      if (!policyEnforcedEntity) {
        throw new Error(`Policy unexpectedly returned no data while analyzing entity ${entityRef} at ${locationRef}`);
      }
      entity = policyEnforcedEntity;
      let handled = false;
      for (const processor of this.options.processors) {
        if (processor.validateEntityKind) {
          try {
            handled = await processor.validateEntityKind(entity);
            if (handled) {
              break;
            }
          } catch (e) {
            throw new errors.InputError(`Processor ${processor.constructor.name} threw an error while validating the entity ${entityRef} at ${locationRef}, ${e}`);
          }
        }
      }
      if (!handled) {
        throw new errors.InputError(`No processor recognized the entity ${entityRef} at ${locationRef}`);
      }
      if (isLocationEntity(entity)) {
        const {type = location.type} = entity.spec;
        const targets = new Array();
        if (entity.spec.target) {
          targets.push(entity.spec.target);
        }
        if (entity.spec.targets) {
          targets.push(...entity.spec.targets);
        }
        for (const maybeRelativeTarget of targets) {
          if (type === "file" && maybeRelativeTarget.endsWith(path__default['default'].sep)) {
            emitter.emit(inputError(location, `LocationEntityProcessor cannot handle ${type} type location with target ${location.target} that ends with a path separator`));
            continue;
          }
          const target = toAbsoluteUrl$1(this.options.integrations, location, type, maybeRelativeTarget);
          for (const processor of this.options.processors) {
            if (processor.readLocation) {
              try {
                const read = await processor.readLocation({
                  type,
                  target,
                  presence: "required"
                }, false, emitter.emit, this.options.parser);
                if (read) {
                  break;
                }
              } catch (e) {
                throw new Error(`Processor ${processor.constructor.name} threw an error while postprocessing entity ${entityRef} at ${locationRef}, ${e}`);
              }
            }
          }
        }
      }
      for (const processor of this.options.processors) {
        if (processor.postProcessEntity) {
          try {
            entity = await processor.postProcessEntity(entity, location, emitter.emit);
          } catch (e) {
            throw new Error(`Processor ${processor.constructor.name} threw an error while postprocessing entity ${entityRef} at ${locationRef}, ${e}`);
          }
        }
      }
      return {
        ...emitter.results(),
        completedEntity: entity,
        state: new Map(),
        ok: true
      };
    } catch (error) {
      this.options.logger.warn(error.message);
      return {ok: false, errors: emitter.results().errors.concat(error)};
    }
  }
}
function createEmitter(logger, parentEntity) {
  let done = false;
  const errors = new Array();
  const relations = new Array();
  const deferredEntities = new Array();
  const emit = (i) => {
    if (done) {
      logger.warn(`Item if type ${i.type} was emitted after processing had completed at ${new Error().stack}`);
      return;
    }
    if (i.type === "entity") {
      const originLocation = getEntityOriginLocationRef(parentEntity);
      deferredEntities.push({
        ...i.entity,
        metadata: {
          ...i.entity.metadata,
          annotations: {
            ...i.entity.metadata.annotations,
            [catalogModel.ORIGIN_LOCATION_ANNOTATION]: originLocation,
            [catalogModel.LOCATION_ANNOTATION]: catalogModel.stringifyLocationReference(i.location)
          }
        }
      });
    } else if (i.type === "location") {
      deferredEntities.push(locationSpecToLocationEntity(i.location, parentEntity));
    } else if (i.type === "relation") {
      relations.push(i.relation);
    } else if (i.type === "error") {
      errors.push(i.error);
    }
  };
  return {
    emit,
    results() {
      done = true;
      return {
        errors,
        relations,
        deferredEntities
      };
    }
  };
}

class DefaultLocationService {
  constructor(store, orchestrator) {
    this.store = store;
    this.orchestrator = orchestrator;
  }
  async createLocation(spec, dryRun) {
    if (dryRun) {
      return this.dryRunCreateLocation(spec);
    }
    const location = await this.store.createLocation(spec);
    return {location, entities: []};
  }
  listLocations() {
    return this.store.listLocations();
  }
  getLocation(id) {
    return this.store.getLocation(id);
  }
  deleteLocation(id) {
    return this.store.deleteLocation(id);
  }
  async dryRunCreateLocation(spec) {
    const entity = {
      apiVersion: "backstage.io/v1alpha1",
      kind: "Location",
      metadata: {
        name: locationSpecToMetadataName({
          type: spec.type,
          target: spec.target
        }),
        namespace: "default",
        annotations: {
          [catalogModel.LOCATION_ANNOTATION]: `${spec.type}:${spec.target}`,
          [catalogModel.ORIGIN_LOCATION_ANNOTATION]: `${spec.type}:${spec.target}`
        }
      },
      spec: {
        type: spec.type,
        target: spec.target
      }
    };
    const unprocessedEntities = [entity];
    const entities = [];
    const state = new Map();
    while (unprocessedEntities.length) {
      const currentEntity = unprocessedEntities.pop();
      if (!currentEntity) {
        continue;
      }
      const processed = await this.orchestrator.process({
        entity: currentEntity,
        state
      });
      if (processed.ok) {
        unprocessedEntities.push(...processed.deferredEntities);
        entities.push(processed.completedEntity);
      } else {
        throw Error(processed.errors.map(String).join(", "));
      }
    }
    return {
      location: {...spec, id: `${spec.type}:${spec.target}`},
      entities
    };
  }
}

class DefaultLocationStore {
  constructor(db) {
    this.db = db;
  }
  getProviderName() {
    return "DefaultLocationStore";
  }
  async createLocation(spec) {
    const location = await this.db.transaction(async (tx) => {
      const previousLocations = await this.locations(tx);
      const previousLocation = previousLocations.some((l) => spec.type === l.type && spec.target === l.target);
      if (previousLocation) {
        throw new errors.ConflictError(`Location ${spec.type}:${spec.target} already exists`);
      }
      const inner = {
        id: uuid.v4(),
        type: spec.type,
        target: spec.target
      };
      await tx("locations").insert(inner);
      return inner;
    });
    await this.connection.applyMutation({
      type: "delta",
      added: [locationSpecToLocationEntity(location)],
      removed: []
    });
    return location;
  }
  async listLocations() {
    return await this.locations();
  }
  async getLocation(id) {
    const items = await this.db("locations").where({id}).select();
    if (!items.length) {
      throw new errors.NotFoundError(`Found no location with ID ${id}`);
    }
    return items[0];
  }
  async deleteLocation(id) {
    if (!this.connection) {
      throw new Error("location store is not initialized");
    }
    const deleted = await this.db.transaction(async (tx) => {
      const [location] = await tx("locations").where({id}).select();
      if (!location) {
        throw new errors.NotFoundError(`Found no location with ID ${id}`);
      }
      await tx("locations").where({id}).del();
      return location;
    });
    await this.connection.applyMutation({
      type: "delta",
      added: [],
      removed: [locationSpecToLocationEntity(deleted)]
    });
  }
  get connection() {
    if (!this._connection) {
      throw new Error("location store is not initialized");
    }
    return this._connection;
  }
  async connect(connection) {
    this._connection = connection;
    const locations = await this.locations();
    const entities = locations.map((location) => {
      return locationSpecToLocationEntity(location);
    });
    await this.connection.applyMutation({
      type: "full",
      entities
    });
  }
  async locations(dbOrTx = this.db) {
    const locations = await dbOrTx("locations").select();
    return locations.filter(({type}) => type !== "bootstrap").map((item) => ({
      id: item.id,
      target: item.target,
      type: item.type
    }));
  }
}

function parsePagination$1(input) {
  if (!input) {
    return {};
  }
  let {limit, offset} = input;
  if (input.after !== void 0) {
    let cursor;
    try {
      const json = Buffer.from(input.after, "base64").toString("utf8");
      cursor = JSON.parse(json);
    } catch {
      throw new errors.InputError("Malformed after cursor, could not be parsed");
    }
    if (cursor.limit !== void 0) {
      if (!Number.isInteger(cursor.limit)) {
        throw new errors.InputError("Malformed after cursor, limit was not an number");
      }
      limit = cursor.limit;
    }
    if (cursor.offset !== void 0) {
      if (!Number.isInteger(cursor.offset)) {
        throw new errors.InputError("Malformed after cursor, offset was not a number");
      }
      offset = cursor.offset;
    }
  }
  return {limit, offset};
}
function stringifyPagination$1(input) {
  const json = JSON.stringify({limit: input.limit, offset: input.offset});
  const base64 = Buffer.from(json, "utf8").toString("base64");
  return base64;
}
class NextEntitiesCatalog {
  constructor(database) {
    this.database = database;
  }
  async entities(request) {
    var _a, _b;
    const db = this.database;
    let entitiesQuery = db("final_entities");
    for (const singleFilter of (_b = (_a = request == null ? void 0 : request.filter) == null ? void 0 : _a.anyOf) != null ? _b : []) {
      entitiesQuery = entitiesQuery.orWhere(function singleFilterFn() {
        for (const {key, matchValueIn} of singleFilter.allOf) {
          const matchQuery = db("search").select("entity_id").where(function keyFilter() {
            this.andWhere({key: key.toLowerCase()});
            if (matchValueIn) {
              if (matchValueIn.length === 1) {
                this.andWhere({value: matchValueIn[0].toLowerCase()});
              } else if (matchValueIn.length > 1) {
                this.andWhere("value", "in", matchValueIn.map((v) => v.toLowerCase()));
              }
            }
          });
          this.andWhere("entity_id", "in", matchQuery);
        }
      });
    }
    entitiesQuery = entitiesQuery.select("final_entities.*").orderBy("entity_id", "asc");
    const {limit, offset} = parsePagination$1(request == null ? void 0 : request.pagination);
    if (limit !== void 0) {
      entitiesQuery = entitiesQuery.limit(limit + 1);
    }
    if (offset !== void 0) {
      entitiesQuery = entitiesQuery.offset(offset);
    }
    let rows = await entitiesQuery;
    let pageInfo;
    if (limit === void 0 || rows.length <= limit) {
      pageInfo = {hasNextPage: false};
    } else {
      rows = rows.slice(0, -1);
      pageInfo = {
        hasNextPage: true,
        endCursor: stringifyPagination$1({
          limit,
          offset: (offset != null ? offset : 0) + limit
        })
      };
    }
    return {
      entities: rows.map((e) => JSON.parse(e.final_entity)),
      pageInfo
    };
  }
  async removeEntityByUid(uid) {
    await this.database("refresh_state").where("entity_id", uid).delete();
  }
  async batchAddOrUpdateEntities() {
    throw new Error("Not implemented");
  }
}

const SPECIAL_KEYS$1 = [
  "attachments",
  "relations",
  "status",
  "metadata.name",
  "metadata.namespace",
  "metadata.uid",
  "metadata.etag",
  "metadata.generation"
];
const MAX_KEY_LENGTH$1 = 200;
const MAX_VALUE_LENGTH$1 = 200;
function traverse$1(root) {
  const output = [];
  function visit(path, current) {
    if (SPECIAL_KEYS$1.includes(path)) {
      return;
    }
    if (current === void 0 || current === null || ["string", "number", "boolean"].includes(typeof current)) {
      output.push({key: path, value: current});
      return;
    }
    if (typeof current !== "object") {
      return;
    }
    if (Array.isArray(current)) {
      for (const item of current) {
        visit(path, item);
        if (typeof item === "string") {
          output.push({key: `${path}.${item}`, value: true});
        }
      }
      return;
    }
    for (const [key, value] of Object.entries(current)) {
      visit(path ? `${path}.${key}` : key, value);
    }
  }
  visit("", root);
  return output;
}
function mapToRows$1(input, entityId) {
  const result = [];
  for (const {key: rawKey, value: rawValue} of input) {
    const key = rawKey.toLocaleLowerCase("en-US");
    if (rawValue === void 0 || rawValue === null) {
      result.push({entity_id: entityId, key, value: null});
    } else {
      const value = String(rawValue).toLocaleLowerCase("en-US");
      if (key.length <= MAX_KEY_LENGTH$1 && value.length <= MAX_VALUE_LENGTH$1) {
        result.push({entity_id: entityId, key, value});
      }
    }
  }
  return result;
}
function buildEntitySearch$1(entityId, entity) {
  var _a;
  const raw = traverse$1(entity);
  raw.push({key: "metadata.name", value: entity.metadata.name});
  raw.push({key: "metadata.namespace", value: entity.metadata.namespace});
  raw.push({key: "metadata.uid", value: entity.metadata.uid});
  if (!entity.metadata.namespace) {
    raw.push({key: "metadata.namespace", value: catalogModel.ENTITY_DEFAULT_NAMESPACE});
  }
  for (const relation of (_a = entity.relations) != null ? _a : []) {
    raw.push({
      key: `relations.${relation.type}`,
      value: catalogModel.stringifyEntityRef(relation.target)
    });
  }
  return mapToRows$1(raw, entityId);
}

const BATCH_SIZE$3 = 50;
function generateStableHash(entity) {
  return crypto.createHash("sha1").update(stableStringify__default['default']({...entity})).digest("hex");
}
class Stitcher {
  constructor(database, logger) {
    this.database = database;
    this.logger = logger;
  }
  async stitch(entityRefs) {
    for (const entityRef of entityRefs) {
      await this.transaction(async (txOpaque) => {
        const tx = txOpaque;
        const result = await tx.with("incoming_references", function incomingReferences(builder) {
          return builder.from("refresh_state_references").where({target_entity_ref: entityRef}).count({count: "*"});
        }).select({
          entityId: "refresh_state.entity_id",
          processedEntity: "refresh_state.processed_entity",
          errors: "refresh_state.errors",
          incomingReferenceCount: "incoming_references.count",
          previousHash: "final_entities.hash",
          relationType: "relations.type",
          relationTarget: "relations.target_entity_ref"
        }).from("refresh_state").where({"refresh_state.entity_ref": entityRef}).crossJoin(tx.raw("incoming_references")).leftOuterJoin("final_entities", {
          "final_entities.entity_id": "refresh_state.entity_id"
        }).leftOuterJoin("relations", {
          "relations.source_entity_ref": "refresh_state.entity_ref"
        }).orderBy("relationType", "asc").orderBy("relationTarget", "asc");
        if (!result.length) {
          this.logger.debug(`Unable to stitch ${entityRef}, item does not exist in refresh state table`);
          return;
        }
        const {
          entityId,
          processedEntity,
          errors,
          incomingReferenceCount,
          previousHash
        } = result[0];
        if (!processedEntity) {
          this.logger.debug(`Unable to stitch ${entityRef}, the entity has not yet been processed`);
          return;
        }
        const entity = JSON.parse(processedEntity);
        const isOrphan = Number(incomingReferenceCount) === 0;
        const processingStatus = {};
        if (isOrphan) {
          this.logger.debug(`${entityRef} is an orphan`);
          entity.metadata.annotations = {
            ...entity.metadata.annotations,
            ["backstage.io/orphan"]: "true"
          };
        }
        if (errors) {
          const parsedErrors = JSON.parse(errors);
          if (Array.isArray(parsedErrors) && parsedErrors.length) {
            processingStatus.errors = parsedErrors;
          }
        }
        entity.relations = result.filter((row) => row.relationType).map((row) => ({
          type: row.relationType,
          target: catalogModel.parseEntityRef(row.relationTarget)
        }));
        entity.status = {
          ...entity.status,
          "backstage.io/catalog-processing": processingStatus
        };
        const hash = generateStableHash(entity);
        if (hash === previousHash) {
          this.logger.debug(`Skipped stitching of ${entityRef}, no changes`);
          return;
        }
        entity.metadata.uid = entityId;
        entity.metadata.generation = 1;
        if (!entity.metadata.etag) {
          entity.metadata.etag = hash;
        }
        await tx("final_entities").insert({
          entity_id: entityId,
          final_entity: JSON.stringify(entity),
          hash
        }).onConflict("entity_id").merge(["final_entity", "hash"]);
        const searchEntries = buildEntitySearch$1(entityId, entity);
        await tx("search").where({entity_id: entityId}).delete();
        await tx.batchInsert("search", searchEntries, BATCH_SIZE$3);
      });
    }
  }
  async transaction(fn) {
    try {
      let result = void 0;
      await this.database.transaction(async (tx) => {
        result = await fn(tx);
      }, {
        doNotRejectOnRollback: true,
        isolationLevel: this.database.client.config.client === "sqlite3" ? void 0 : "serializable"
      });
      return result;
    } catch (e) {
      this.logger.debug(`Error during transaction, ${e}`);
      if (/SQLITE_CONSTRAINT: UNIQUE/.test(e.message) || /unique constraint/.test(e.message)) {
        throw new errors.ConflictError(`Rejected due to a conflicting entity`, e);
      }
      throw e;
    }
  }
}

class NextCatalogBuilder {
  constructor(env) {
    this.env = env;
    this.entityPolicies = [];
    this.entityPoliciesReplace = false;
    this.placeholderResolvers = {};
    this.fieldFormatValidators = {};
    this.processors = [];
    this.processorsReplace = false;
    this.parser = void 0;
  }
  addEntityPolicy(...policies) {
    this.entityPolicies.push(...policies);
    return this;
  }
  replaceEntityPolicies(policies) {
    this.entityPolicies = [...policies];
    this.entityPoliciesReplace = true;
    return this;
  }
  setPlaceholderResolver(key, resolver) {
    this.placeholderResolvers[key] = resolver;
    return this;
  }
  setFieldFormatValidators(validators) {
    lodash__default['default'].merge(this.fieldFormatValidators, validators);
    return this;
  }
  addProcessor(...processors) {
    this.processors.push(...processors);
    return this;
  }
  replaceProcessors(processors) {
    this.processors = [...processors];
    this.processorsReplace = true;
    return this;
  }
  setEntityDataParser(parser) {
    this.parser = parser;
    return this;
  }
  async build() {
    const {config, database, logger} = this.env;
    const policy = this.buildEntityPolicy();
    const processors = this.buildProcessors();
    const parser = this.parser || defaultEntityDataParser;
    const dbClient = await database.getClient();
    await dbClient.migrate.latest({
      directory: backendCommon.resolvePackagePath("@backstage/plugin-catalog-backend", "migrationsv2")
    });
    const db = new CommonDatabase(dbClient, logger);
    const processingDatabase = new DefaultProcessingDatabase(dbClient, logger);
    const integrations = integration.ScmIntegrations.fromConfig(config);
    const orchestrator = new DefaultCatalogProcessingOrchestrator({
      processors,
      integrations,
      logger,
      parser,
      policy
    });
    const entitiesCatalog = new NextEntitiesCatalog(dbClient);
    const locationStore = new DefaultLocationStore(dbClient);
    const stitcher = new Stitcher(dbClient, logger);
    const configLocationProvider = new ConfigLocationEntityProvider(config);
    const processingEngine = new DefaultCatalogProcessingEngine(logger, [locationStore, configLocationProvider], processingDatabase, orchestrator, stitcher);
    const locationsCatalog = new DatabaseLocationsCatalog(db);
    const locationAnalyzer = new RepoLocationAnalyzer(logger, integrations);
    const locationService = new DefaultLocationService(locationStore, orchestrator);
    return {
      entitiesCatalog,
      locationsCatalog,
      locationAnalyzer,
      processingEngine,
      locationService
    };
  }
  buildEntityPolicy() {
    const entityPolicies = this.entityPoliciesReplace ? [new catalogModel.SchemaValidEntityPolicy(), ...this.entityPolicies] : [
      new catalogModel.SchemaValidEntityPolicy(),
      new catalogModel.DefaultNamespaceEntityPolicy(),
      new catalogModel.NoForeignRootFieldsEntityPolicy(),
      new catalogModel.FieldFormatEntityPolicy(catalogModel.makeValidator(this.fieldFormatValidators)),
      ...this.entityPolicies
    ];
    return catalogModel.EntityPolicies.allOf(entityPolicies);
  }
  buildProcessors() {
    const {config, logger, reader} = this.env;
    const integrations = integration.ScmIntegrations.fromConfig(config);
    this.checkDeprecatedReaderProcessors();
    const placeholderResolvers = {
      json: jsonPlaceholderResolver,
      yaml: yamlPlaceholderResolver,
      text: textPlaceholderResolver,
      ...this.placeholderResolvers
    };
    const processors = [
      new PlaceholderProcessor({resolvers: placeholderResolvers, reader}),
      new BuiltinKindsEntityProcessor()
    ];
    if (!this.processorsReplace) {
      processors.push(new FileReaderProcessor(), BitbucketDiscoveryProcessor.fromConfig(config, {logger}), GithubDiscoveryProcessor.fromConfig(config, {logger}), GithubOrgReaderProcessor.fromConfig(config, {logger}), LdapOrgReaderProcessor.fromConfig(config, {logger}), MicrosoftGraphOrgReaderProcessor.fromConfig(config, {logger}), new UrlReaderProcessor({reader, logger}), CodeOwnersProcessor.fromConfig(config, {logger, reader}), new AnnotateLocationEntityProcessor({integrations}));
    }
    processors.push(...this.processors);
    return processors;
  }
  checkDeprecatedReaderProcessors() {
    const pc = this.env.config.getOptionalConfig("catalog.processors");
    if (pc == null ? void 0 : pc.has("github")) {
      throw new Error(`Using deprecated configuration for catalog.processors.github, move to using integrations.github instead`);
    }
    if (pc == null ? void 0 : pc.has("gitlabApi")) {
      throw new Error(`Using deprecated configuration for catalog.processors.gitlabApi, move to using integrations.gitlab instead`);
    }
    if (pc == null ? void 0 : pc.has("bitbucketApi")) {
      throw new Error(`Using deprecated configuration for catalog.processors.bitbucketApi, move to using integrations.bitbucket instead`);
    }
    if (pc == null ? void 0 : pc.has("azureApi")) {
      throw new Error(`Using deprecated configuration for catalog.processors.azureApi, move to using integrations.azure instead`);
    }
  }
}

async function createNextRouter(options) {
  const {
    entitiesCatalog,
    locationAnalyzer,
    locationService,
    config,
    logger
  } = options;
  const router = Router__default['default']();
  router.use(express__default['default'].json());
  const readonlyEnabled = config.getOptionalBoolean("catalog.readonly") || false;
  if (readonlyEnabled) {
    logger.info("Catalog is running in readonly mode");
  }
  if (entitiesCatalog) {
    router.get("/entities", async (req, res) => {
      const {entities, pageInfo} = await entitiesCatalog.entities({
        filter: parseEntityFilterParams(req.query),
        fields: parseEntityTransformParams(req.query),
        pagination: parseEntityPaginationParams(req.query)
      });
      if (pageInfo.hasNextPage) {
        const url = new URL(`http://ignored${req.url}`);
        url.searchParams.delete("offset");
        url.searchParams.set("after", pageInfo.endCursor);
        res.setHeader("link", `<${url.pathname}${url.search}>; rel="next"`);
      }
      res.json(entities);
    }).get("/entities/by-uid/:uid", async (req, res) => {
      const {uid} = req.params;
      const {entities} = await entitiesCatalog.entities({
        filter: basicEntityFilter({"metadata.uid": uid})
      });
      if (!entities.length) {
        throw new errors.NotFoundError(`No entity with uid ${uid}`);
      }
      res.status(200).json(entities[0]);
    }).delete("/entities/by-uid/:uid", async (req, res) => {
      const {uid} = req.params;
      await entitiesCatalog.removeEntityByUid(uid);
      res.status(204).end();
    }).get("/entities/by-name/:kind/:namespace/:name", async (req, res) => {
      const {kind, namespace, name} = req.params;
      const {entities} = await entitiesCatalog.entities({
        filter: basicEntityFilter({
          kind,
          "metadata.namespace": namespace,
          "metadata.name": name
        })
      });
      if (!entities.length) {
        throw new errors.NotFoundError(`No entity named '${name}' found, with kind '${kind}' in namespace '${namespace}'`);
      }
      res.status(200).json(entities[0]);
    });
  }
  if (locationService) {
    router.post("/locations", async (req, res) => {
      const input = await validateRequestBody(req, catalogModel.locationSpecSchema);
      const dryRun = yn__default['default'](req.query.dryRun, {default: false});
      if (!dryRun) {
        disallowReadonlyMode(readonlyEnabled);
      }
      const output = await locationService.createLocation(input, dryRun);
      res.status(201).json(output);
    }).get("/locations", async (_req, res) => {
      const locations = await locationService.listLocations();
      res.status(200).json(locations.map((l) => ({data: l})));
    }).get("/locations/:id", async (req, res) => {
      const {id} = req.params;
      const output = await locationService.getLocation(id);
      res.status(200).json(output);
    }).delete("/locations/:id", async (req, res) => {
      disallowReadonlyMode(readonlyEnabled);
      const {id} = req.params;
      await locationService.deleteLocation(id);
      res.status(204).end();
    });
  }
  if (locationAnalyzer) {
    router.post("/analyze-location", async (req, res) => {
      const input = await validateRequestBody(req, catalogModel.analyzeLocationSchema);
      const output = await locationAnalyzer.analyzeLocation(input);
      res.status(200).json(output);
    });
  }
  router.use(backendCommon.errorHandler());
  return router;
}

exports.AnnotateLocationEntityProcessor = AnnotateLocationEntityProcessor;
exports.AnnotateScmSlugEntityProcessor = AnnotateScmSlugEntityProcessor;
exports.AwsOrganizationCloudAccountProcessor = AwsOrganizationCloudAccountProcessor;
exports.BitbucketDiscoveryProcessor = BitbucketDiscoveryProcessor;
exports.BuiltinKindsEntityProcessor = BuiltinKindsEntityProcessor;
exports.CatalogBuilder = CatalogBuilder;
exports.CodeOwnersProcessor = CodeOwnersProcessor;
exports.CommonDatabase = CommonDatabase;
exports.DatabaseEntitiesCatalog = DatabaseEntitiesCatalog;
exports.DatabaseLocationsCatalog = DatabaseLocationsCatalog;
exports.DatabaseManager = DatabaseManager;
exports.DefaultCatalogCollator = DefaultCatalogCollator;
exports.FileReaderProcessor = FileReaderProcessor;
exports.GithubDiscoveryProcessor = GithubDiscoveryProcessor;
exports.GithubOrgReaderProcessor = GithubOrgReaderProcessor;
exports.HigherOrderOperations = HigherOrderOperations;
exports.LdapOrgReaderProcessor = LdapOrgReaderProcessor;
exports.LocationEntityProcessor = LocationEntityProcessor;
exports.LocationReaders = LocationReaders;
exports.MicrosoftGraphOrgReaderProcessor = MicrosoftGraphOrgReaderProcessor;
exports.NextCatalogBuilder = NextCatalogBuilder;
exports.PlaceholderProcessor = PlaceholderProcessor;
exports.StaticLocationProcessor = StaticLocationProcessor;
exports.UrlReaderProcessor = UrlReaderProcessor;
exports.createNextRouter = createNextRouter;
exports.createRouter = createRouter;
exports.durationText = durationText;
exports.parseEntityYaml = parseEntityYaml;
exports.results = results;
exports.runPeriodically = runPeriodically;
//# sourceMappingURL=index.cjs.js.map
